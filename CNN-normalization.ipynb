{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code shows how images, specifically vehicle images like cars, trucks, vans, bikes, motorcycles and others, can be classified using Convolutional Neural Network (CNN). This code is built based on an image classifier developed for the \"Applied Data Science: Machine Learning\" Program from the EPFL Lausanne.\n",
    "The dataset consists of Swissroads data set which contains several hundreds images of vehicles found in the EPFL - Lausanne area including cars, trucks, vans, bikes, motorcycles and others. The dataset is quite small, hence the results, but could easily be extended to include other datasets and other vehicles classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter warnings\n",
    "import warnings\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "# keras imports\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D, BatchNormalization\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras import backend as K \n",
    "\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import math\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "# load all images in a directory\n",
    "from os import listdir\n",
    "from matplotlib import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "EPOCHS = 500\n",
    "IMG_HEIGHT = 256\n",
    "IMG_WIDTH = 256\n",
    "NUM_CLASSES = 6\n",
    "IMG_SIZE = (IMG_HEIGHT, IMG_WIDTH)\n",
    "LEARNING_RATE = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = os.getcwd()  # Get the current working directory\n",
    "data_dir = os.path.join(base_dir, 'swissroads')\n",
    "train_dir = os.path.join(data_dir, 'train')\n",
    "test_dir = os.path.join(data_dir, 'test')\n",
    "valid_dir = os.path.join(data_dir, 'valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(img_folder):\n",
    "   \n",
    "    img_data_array=[]\n",
    "    class_name=[]\n",
    "   \n",
    "    for dir1 in os.listdir(img_folder):\n",
    "        if not dir1.endswith(\".DS_Store\"):\n",
    "\n",
    "            for file in os.listdir(os.path.join(img_folder, dir1)):\n",
    "                if file.endswith(\".png\"):\n",
    "                    image_path = os.path.join(img_folder, dir1,  file)\n",
    "                    image= cv2.imread( image_path, cv2.COLOR_BGR2RGB)\n",
    "                    image=cv2.resize(image, (IMG_HEIGHT, IMG_WIDTH),interpolation = cv2.INTER_AREA)\n",
    "                    image=np.array(image)\n",
    "                    image = image.astype('float32')\n",
    "                    image /= 255 \n",
    "                    img_data_array.append(image)\n",
    "                    class_name.append(dir1)\n",
    "    return img_data_array, class_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the image array and class name\n",
    "x_train, y_train = create_dataset(train_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the image array and class name\n",
    "x_val, y_val = create_dataset(valid_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the image array and class name\n",
    "x_test, y_test = create_dataset(test_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "**Utility functions**\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams['figure.figsize'] = (12, 10)\n",
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(history, label, n):\n",
    "  # Use a log scale to show the wide range of values.\n",
    "    plt.semilogy(history.epoch,  history.history['loss'], color = colors[n], label = 'Train ' + label)\n",
    "    plt.semilogy(history.epoch,  history.history['val_loss'], color = colors[n], label = 'Val ' + label, linestyle = \"--\")\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "  \n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_accuracy(history, label, n):\n",
    "  # Use a log scale to show the wide range of values.\n",
    "    plt.semilogy(history.epoch,  history.history['accuracy'], color = colors[n], label = 'Train ' + label)\n",
    "    plt.semilogy(history.epoch,  history.history['val_accuracy'], color = colors[n], label = 'Val ' + label, linestyle = \"--\")\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "  \n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics(history):\n",
    "    metrics = ['loss', 'accuracy']\n",
    "    for n, metric in enumerate(metrics):\n",
    "        name = metric.replace(\"_\",\" \").capitalize()\n",
    "        plt.subplot(2, 2, n+1)\n",
    "        plt.plot(history.epoch,  history.history[metric], color = colors[0], label = 'Train')\n",
    "        plt.plot(history.epoch, history.history['val_' + metric], color = colors[1], linestyle = \"--\", label = 'Val')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel(name)\n",
    "        if metric == 'loss':\n",
    "            plt.ylim([0, plt.ylim()[1]])\n",
    "        else:\n",
    "            plt.ylim([0,1])\n",
    "        plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cspace_transf(image):\n",
    "    image = np.array(image)\n",
    "    return cv2.cvtColor(image,cv2.COLOR_RGB2XYZ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "**Using image data augmentation**\n",
    "***\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply data augmentation to improve overfitting\n",
    "train_image_generator = ImageDataGenerator(\n",
    "                    featurewise_center=True,\n",
    "                    featurewise_std_normalization=True\n",
    ") # Generator for our training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_generator.fit(x_train) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "**Standardizing the data**\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_generator.fit(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_generator.fit(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "**Data pre-processing**\n",
    "***\n",
    "In Keras this can be done via the keras.preprocessing.image.ImageDataGenerator class. This class allows to:\n",
    "\n",
    "- configure random transformations and normalization operations to be done on your image data during training\n",
    "- instantiate generators of augmented image batches (and their labels) via .flow(data, labels) or .flow_from_directory(directory). These generators can then be used with the Keras model methods that accept data generators as inputs, fit_generator, evaluate_generator and predict_generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 280 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "train_data_gen = train_image_generator.flow_from_directory(batch_size = BATCH_SIZE,\n",
    "                                                           directory = train_dir,\n",
    "                                                           shuffle = True,\n",
    "                                                           target_size = IMG_SIZE,\n",
    "                                                           class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 139 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "valid_data_gen = train_image_generator.flow_from_directory(batch_size = BATCH_SIZE,\n",
    "                                                           directory = valid_dir,\n",
    "                                                           shuffle = True,\n",
    "                                                           target_size = IMG_SIZE,\n",
    "                                                           class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 50 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "test_data_gen = train_image_generator.flow_from_directory(batch_size = BATCH_SIZE,\n",
    "                                                           directory = test_dir,\n",
    "                                                           shuffle = True,\n",
    "                                                           target_size = IMG_SIZE,\n",
    "                                                           class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part is to check the data format i.e if the RGB channel is coming first or last so that whatever it may be, the model will first check and then get the appropriate input shape be fed accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "if K.image_data_format() == 'channels_first': \n",
    "    input_shape = (3, IMG_WIDTH, IMG_HEIGHT) \n",
    "else: \n",
    "    input_shape = (IMG_WIDTH, IMG_HEIGHT, 3) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "**Build the model**\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The architectural decisions we will be making are the number of layers, the number of filters, and the size of the filters. In our case we will use a rather small convnet with few layers and few filters per layer, alongside data augmentation and dropout. Dropout also helps reduce overfitting, by preventing a layer from seeing twice the exact same pattern, thus acting in a way analoguous to data augmentation (you could say that both dropout and data augmentation tend to disrupt random correlations occuring in the data). \n",
    "\n",
    "This is very similar to the architectures that Yann LeCun advocated in the 1990s for image classification (with the exception of ReLU).\n",
    "\n",
    "- **Conv2D** is the layer to convolve the image into multiple images\n",
    "- **Activation** is the activation function.\n",
    "- **MaxPooling2D** is used to max pool the value from the given size matrix and same is used for the next 2 layers. then, Flatten is used to flatten the dimensions of the image obtained after convolving it.\n",
    "- **Dense** is used to make this a fully connected model and is the hidden layer.\n",
    "- **Dropout** is used to avoid overfitting on the dataset.\n",
    "- **Dense** is the output layer contains only one neuron which decide to which category image belongs.\n",
    "\n",
    "Typically the number of layers starts small and grows as the complexity realized by the convoluted layers grows. The number of filters in a layer should be set at ratios of 32, 64, 128, 256, 512 and so on according to one source. In this case I have decided to play a bit with the number of filters and see if smaller values will show improvement.\n",
    "\n",
    "Filters have odd values since they need to be centered on the pixel being convolved. A 3x3 filter is usual although larger ones of 5x5 up to 7x7 may work better on larger images. Max pool layers typically have a pool size of (2, 2) and are applied after each convolutional layer.\n",
    "\n",
    "After flattening I use a heavy dropout to prevent overfitting. \n",
    "\n",
    "The model was given a single dense layer with activation set to 'relu' as usual. The number of output elements is always set to the number of classes and activation to 'softmax'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model():\n",
    "        \n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(16, kernel_size=(3, 3), activation='relu', padding='same', input_shape=input_shape))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Conv2D(16, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(NUM_CLASSES, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer = Adam(lr = LEARNING_RATE), metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "**Model Architecture**\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Early stopping**\n",
    "\n",
    "When we’re training a learning algorithm iteratively, we can measure how well each iteration of the model performs. Up until a certain number of iterations, new iterations improve the model. After that point, however, the model’s ability to generalize can weaken as it begins to overfit the training data. Early stopping refers stopping the training process before the learner passes that point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor = 'val_accuracy', \n",
    "    verbose = 2,\n",
    "    patience = 30,\n",
    "    mode = 'max',\n",
    "    restore_best_weights = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [early_stopping]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_STEPS = int(np.ceil(train_data_gen.n / float(BATCH_SIZE)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "VALIDATION_STEPS = int(np.ceil(valid_data_gen.n / float(BATCH_SIZE)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_STEPS = int(np.ceil(test_data_gen.n / float(BATCH_SIZE)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 256, 256, 16)      448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 128, 128, 16)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 128, 128, 16)      64        \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128, 128, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 128, 128, 16)      2320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 64, 64, 16)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 64, 64, 16)        64        \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64, 64, 16)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 65536)             0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 65536)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                4194368   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 4,197,654\n",
      "Trainable params: 4,197,590\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = make_model()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "**Train the model**\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "18/18 [==============================] - 16s 811ms/step - loss: 3.8785 - accuracy: 0.2152 - val_loss: 17.5309 - val_accuracy: 0.2590\n",
      "Epoch 2/500\n",
      "18/18 [==============================] - 18s 982ms/step - loss: 2.2191 - accuracy: 0.4427 - val_loss: 10.1167 - val_accuracy: 0.2590\n",
      "Epoch 3/500\n",
      "18/18 [==============================] - 14s 795ms/step - loss: 1.6566 - accuracy: 0.5253 - val_loss: 5.5821 - val_accuracy: 0.2446\n",
      "Epoch 4/500\n",
      "18/18 [==============================] - 18s 1s/step - loss: 1.3982 - accuracy: 0.5360 - val_loss: 4.8046 - val_accuracy: 0.2878\n",
      "Epoch 5/500\n",
      "18/18 [==============================] - 26s 1s/step - loss: 1.1419 - accuracy: 0.5994 - val_loss: 3.6424 - val_accuracy: 0.3022\n",
      "Epoch 6/500\n",
      "18/18 [==============================] - 21s 1s/step - loss: 1.0667 - accuracy: 0.6157 - val_loss: 2.4402 - val_accuracy: 0.3237\n",
      "Epoch 7/500\n",
      "18/18 [==============================] - 42s 2s/step - loss: 0.7956 - accuracy: 0.6903 - val_loss: 2.0879 - val_accuracy: 0.3525\n",
      "Epoch 8/500\n",
      "18/18 [==============================] - 25s 1s/step - loss: 0.8315 - accuracy: 0.6543 - val_loss: 1.9318 - val_accuracy: 0.3597\n",
      "Epoch 9/500\n",
      "18/18 [==============================] - 24s 1s/step - loss: 0.7379 - accuracy: 0.7411 - val_loss: 1.8651 - val_accuracy: 0.3669\n",
      "Epoch 10/500\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.6172 - accuracy: 0.7786 - val_loss: 1.7805 - val_accuracy: 0.3813\n",
      "Epoch 11/500\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.5433 - accuracy: 0.7993 - val_loss: 1.7466 - val_accuracy: 0.3669\n",
      "Epoch 12/500\n",
      "18/18 [==============================] - 24s 1s/step - loss: 0.5168 - accuracy: 0.8479 - val_loss: 1.7226 - val_accuracy: 0.3525\n",
      "Epoch 13/500\n",
      "18/18 [==============================] - 24s 1s/step - loss: 0.4862 - accuracy: 0.8036 - val_loss: 1.7413 - val_accuracy: 0.3525\n",
      "Epoch 14/500\n",
      "18/18 [==============================] - 24s 1s/step - loss: 0.3966 - accuracy: 0.8882 - val_loss: 1.7265 - val_accuracy: 0.3885\n",
      "Epoch 15/500\n",
      "18/18 [==============================] - 24s 1s/step - loss: 0.4314 - accuracy: 0.8749 - val_loss: 1.7341 - val_accuracy: 0.3957\n",
      "Epoch 16/500\n",
      "18/18 [==============================] - 25s 1s/step - loss: 0.3912 - accuracy: 0.8513 - val_loss: 1.7329 - val_accuracy: 0.4173\n",
      "Epoch 17/500\n",
      "18/18 [==============================] - 25s 1s/step - loss: 0.3031 - accuracy: 0.8900 - val_loss: 1.7357 - val_accuracy: 0.4029\n",
      "Epoch 18/500\n",
      "18/18 [==============================] - 25s 1s/step - loss: 0.3344 - accuracy: 0.9054 - val_loss: 1.7814 - val_accuracy: 0.3957\n",
      "Epoch 19/500\n",
      "18/18 [==============================] - 24s 1s/step - loss: 0.2668 - accuracy: 0.8915 - val_loss: 1.7879 - val_accuracy: 0.4029\n",
      "Epoch 20/500\n",
      "18/18 [==============================] - 23s 1s/step - loss: 0.3634 - accuracy: 0.8852 - val_loss: 1.7151 - val_accuracy: 0.4101\n",
      "Epoch 21/500\n",
      "18/18 [==============================] - 23s 1s/step - loss: 0.2274 - accuracy: 0.9230 - val_loss: 1.7840 - val_accuracy: 0.3885\n",
      "Epoch 22/500\n",
      "18/18 [==============================] - 23s 1s/step - loss: 0.1974 - accuracy: 0.9200 - val_loss: 1.8611 - val_accuracy: 0.3957\n",
      "Epoch 23/500\n",
      "18/18 [==============================] - 24s 1s/step - loss: 0.3598 - accuracy: 0.8902 - val_loss: 1.8066 - val_accuracy: 0.3813\n",
      "Epoch 24/500\n",
      "18/18 [==============================] - 24s 1s/step - loss: 0.2424 - accuracy: 0.9090 - val_loss: 1.8781 - val_accuracy: 0.4029\n",
      "Epoch 25/500\n",
      "18/18 [==============================] - 25s 1s/step - loss: 0.1766 - accuracy: 0.9417 - val_loss: 1.8704 - val_accuracy: 0.4029\n",
      "Epoch 26/500\n",
      "18/18 [==============================] - 24s 1s/step - loss: 0.1423 - accuracy: 0.9432 - val_loss: 1.9358 - val_accuracy: 0.3957\n",
      "Epoch 27/500\n",
      "18/18 [==============================] - 25s 1s/step - loss: 0.2227 - accuracy: 0.9444 - val_loss: 1.9864 - val_accuracy: 0.3885\n",
      "Epoch 28/500\n",
      "18/18 [==============================] - 27s 1s/step - loss: 0.1946 - accuracy: 0.9339 - val_loss: 1.9727 - val_accuracy: 0.3525\n",
      "Epoch 29/500\n",
      "18/18 [==============================] - 28s 2s/step - loss: 0.2201 - accuracy: 0.9335 - val_loss: 2.0352 - val_accuracy: 0.3885\n",
      "Epoch 30/500\n",
      "18/18 [==============================] - 27s 1s/step - loss: 0.1325 - accuracy: 0.9449 - val_loss: 2.2658 - val_accuracy: 0.3813\n",
      "Epoch 31/500\n",
      "18/18 [==============================] - 26s 1s/step - loss: 0.1424 - accuracy: 0.9510 - val_loss: 2.2819 - val_accuracy: 0.3525\n",
      "Epoch 32/500\n",
      "18/18 [==============================] - 24s 1s/step - loss: 0.1608 - accuracy: 0.9420 - val_loss: 2.2905 - val_accuracy: 0.3813\n",
      "Epoch 33/500\n",
      "18/18 [==============================] - 25s 1s/step - loss: 0.1916 - accuracy: 0.9269 - val_loss: 2.0844 - val_accuracy: 0.3957\n",
      "Epoch 34/500\n",
      "18/18 [==============================] - 26s 1s/step - loss: 0.0833 - accuracy: 0.9703 - val_loss: 2.1675 - val_accuracy: 0.3813\n",
      "Epoch 35/500\n",
      "18/18 [==============================] - 25s 1s/step - loss: 0.0919 - accuracy: 0.9638 - val_loss: 2.2186 - val_accuracy: 0.3669\n",
      "Epoch 36/500\n",
      "18/18 [==============================] - 25s 1s/step - loss: 0.1191 - accuracy: 0.9507 - val_loss: 2.2781 - val_accuracy: 0.3885\n",
      "Epoch 37/500\n",
      "18/18 [==============================] - 24s 1s/step - loss: 0.1311 - accuracy: 0.9457 - val_loss: 2.2751 - val_accuracy: 0.3957\n",
      "Epoch 38/500\n",
      "18/18 [==============================] - 25s 1s/step - loss: 0.2261 - accuracy: 0.9100 - val_loss: 2.4315 - val_accuracy: 0.3957\n",
      "Epoch 39/500\n",
      "18/18 [==============================] - 25s 1s/step - loss: 0.1089 - accuracy: 0.9542 - val_loss: 2.3397 - val_accuracy: 0.3885\n",
      "Epoch 40/500\n",
      "18/18 [==============================] - 25s 1s/step - loss: 0.0742 - accuracy: 0.9797 - val_loss: 2.4392 - val_accuracy: 0.3741\n",
      "Epoch 41/500\n",
      "18/18 [==============================] - 25s 1s/step - loss: 0.0736 - accuracy: 0.9691 - val_loss: 2.4660 - val_accuracy: 0.3813\n",
      "Epoch 42/500\n",
      "18/18 [==============================] - 25s 1s/step - loss: 0.1015 - accuracy: 0.9659 - val_loss: 2.4870 - val_accuracy: 0.3525\n",
      "Epoch 43/500\n",
      "18/18 [==============================] - 25s 1s/step - loss: 0.0865 - accuracy: 0.9656 - val_loss: 2.4606 - val_accuracy: 0.3741\n",
      "Epoch 44/500\n",
      "18/18 [==============================] - 25s 1s/step - loss: 0.0852 - accuracy: 0.9893 - val_loss: 2.3323 - val_accuracy: 0.3885\n",
      "Epoch 45/500\n",
      "18/18 [==============================] - 24s 1s/step - loss: 0.0466 - accuracy: 0.9858 - val_loss: 2.4090 - val_accuracy: 0.3885\n",
      "Epoch 46/500\n",
      "18/18 [==============================] - 24s 1s/step - loss: 0.0389 - accuracy: 0.9835 - val_loss: 2.5563 - val_accuracy: 0.3741\n",
      "Epoch 47/500\n",
      "18/18 [==============================] - 24s 1s/step - loss: 0.0596 - accuracy: 0.9813 - val_loss: 2.5277 - val_accuracy: 0.3669\n",
      "Epoch 48/500\n",
      "18/18 [==============================] - 25s 1s/step - loss: 0.1549 - accuracy: 0.9310 - val_loss: 2.5121 - val_accuracy: 0.3813\n",
      "Epoch 49/500\n",
      "18/18 [==============================] - 25s 1s/step - loss: 0.0886 - accuracy: 0.9727 - val_loss: 2.5719 - val_accuracy: 0.3669\n",
      "Epoch 50/500\n",
      "18/18 [==============================] - 25s 1s/step - loss: 0.0761 - accuracy: 0.9737 - val_loss: 2.6361 - val_accuracy: 0.3741\n",
      "Epoch 51/500\n",
      "18/18 [==============================] - 30s 2s/step - loss: 0.0966 - accuracy: 0.9797 - val_loss: 2.5318 - val_accuracy: 0.4029\n",
      "Epoch 52/500\n",
      "18/18 [==============================] - 28s 2s/step - loss: 0.0965 - accuracy: 0.9676 - val_loss: 2.5156 - val_accuracy: 0.4029\n",
      "Epoch 53/500\n",
      "18/18 [==============================] - 27s 1s/step - loss: 0.0598 - accuracy: 0.9740 - val_loss: 2.5496 - val_accuracy: 0.3957\n",
      "Epoch 54/500\n",
      "18/18 [==============================] - 26s 1s/step - loss: 0.0911 - accuracy: 0.9667 - val_loss: 2.6421 - val_accuracy: 0.3813\n",
      "Epoch 55/500\n",
      "18/18 [==============================] - 25s 1s/step - loss: 0.0904 - accuracy: 0.9744 - val_loss: 2.4777 - val_accuracy: 0.4029\n",
      "Epoch 56/500\n",
      "18/18 [==============================] - 24s 1s/step - loss: 0.0585 - accuracy: 0.9735 - val_loss: 2.4358 - val_accuracy: 0.3885\n",
      "Epoch 57/500\n",
      "18/18 [==============================] - 28s 2s/step - loss: 0.0560 - accuracy: 0.9835 - val_loss: 2.4150 - val_accuracy: 0.4173\n",
      "Epoch 58/500\n",
      "18/18 [==============================] - 23s 1s/step - loss: 0.0598 - accuracy: 0.9774 - val_loss: 2.3468 - val_accuracy: 0.4173\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/500\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.0576 - accuracy: 0.9774 - val_loss: 2.3826 - val_accuracy: 0.4245\n",
      "Epoch 60/500\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.0543 - accuracy: 0.9706 - val_loss: 2.3870 - val_accuracy: 0.4245\n",
      "Epoch 61/500\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.0232 - accuracy: 0.9935 - val_loss: 2.3812 - val_accuracy: 0.4029\n",
      "Epoch 62/500\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.0586 - accuracy: 0.9853 - val_loss: 2.5169 - val_accuracy: 0.4317\n",
      "Epoch 63/500\n",
      "18/18 [==============================] - 23s 1s/step - loss: 0.0762 - accuracy: 0.9520 - val_loss: 2.5982 - val_accuracy: 0.4029\n",
      "Epoch 64/500\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.0437 - accuracy: 0.9820 - val_loss: 2.5442 - val_accuracy: 0.4101\n",
      "Epoch 65/500\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.0409 - accuracy: 0.9839 - val_loss: 2.5435 - val_accuracy: 0.4173\n",
      "Epoch 66/500\n",
      "18/18 [==============================] - 23s 1s/step - loss: 0.1710 - accuracy: 0.9567 - val_loss: 2.5709 - val_accuracy: 0.4317\n",
      "Epoch 67/500\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.0324 - accuracy: 0.9913 - val_loss: 2.5945 - val_accuracy: 0.4317\n",
      "Epoch 68/500\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.1122 - accuracy: 0.9604 - val_loss: 2.6028 - val_accuracy: 0.4460\n",
      "Epoch 69/500\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.0620 - accuracy: 0.9815 - val_loss: 2.7211 - val_accuracy: 0.4029\n",
      "Epoch 70/500\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.0702 - accuracy: 0.9640 - val_loss: 2.7809 - val_accuracy: 0.4173\n",
      "Epoch 71/500\n",
      "18/18 [==============================] - 23s 1s/step - loss: 0.0627 - accuracy: 0.9771 - val_loss: 2.7704 - val_accuracy: 0.4029\n",
      "Epoch 72/500\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.0987 - accuracy: 0.9594 - val_loss: 2.5316 - val_accuracy: 0.4029\n",
      "Epoch 73/500\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.0531 - accuracy: 0.9828 - val_loss: 2.4968 - val_accuracy: 0.4173\n",
      "Epoch 74/500\n",
      "18/18 [==============================] - 21s 1s/step - loss: 0.0267 - accuracy: 0.9976 - val_loss: 2.4377 - val_accuracy: 0.4029\n",
      "Epoch 75/500\n",
      "18/18 [==============================] - 21s 1s/step - loss: 0.0265 - accuracy: 0.9898 - val_loss: 2.5398 - val_accuracy: 0.4101\n",
      "Epoch 76/500\n",
      "18/18 [==============================] - 21s 1s/step - loss: 0.0449 - accuracy: 0.9790 - val_loss: 2.6288 - val_accuracy: 0.4029\n",
      "Epoch 77/500\n",
      "18/18 [==============================] - 21s 1s/step - loss: 0.0318 - accuracy: 0.9873 - val_loss: 2.6224 - val_accuracy: 0.4029\n",
      "Epoch 78/500\n",
      "18/18 [==============================] - 26s 1s/step - loss: 0.0498 - accuracy: 0.9867 - val_loss: 2.8328 - val_accuracy: 0.3885\n",
      "Epoch 79/500\n",
      "18/18 [==============================] - 24s 1s/step - loss: 0.0435 - accuracy: 0.9800 - val_loss: 2.9422 - val_accuracy: 0.3741\n",
      "Epoch 80/500\n",
      "18/18 [==============================] - 28s 2s/step - loss: 0.0701 - accuracy: 0.9643 - val_loss: 2.7665 - val_accuracy: 0.4029\n",
      "Epoch 81/500\n",
      "18/18 [==============================] - 25s 1s/step - loss: 0.0252 - accuracy: 0.9961 - val_loss: 2.7003 - val_accuracy: 0.4101\n",
      "Epoch 82/500\n",
      "18/18 [==============================] - 28s 2s/step - loss: 0.0250 - accuracy: 0.9958 - val_loss: 2.7007 - val_accuracy: 0.4245\n",
      "Epoch 83/500\n",
      "18/18 [==============================] - 28s 2s/step - loss: 0.0490 - accuracy: 0.9852 - val_loss: 2.7938 - val_accuracy: 0.4173\n",
      "Epoch 84/500\n",
      "18/18 [==============================] - 31s 2s/step - loss: 0.0472 - accuracy: 0.9717 - val_loss: 2.7048 - val_accuracy: 0.4173\n",
      "Epoch 85/500\n",
      "18/18 [==============================] - 25s 1s/step - loss: 0.0271 - accuracy: 0.9899 - val_loss: 2.7607 - val_accuracy: 0.4101\n",
      "Epoch 86/500\n",
      "18/18 [==============================] - 26s 1s/step - loss: 0.0543 - accuracy: 0.9886 - val_loss: 2.6669 - val_accuracy: 0.4029\n",
      "Epoch 87/500\n",
      "18/18 [==============================] - 23s 1s/step - loss: 0.0801 - accuracy: 0.9587 - val_loss: 2.7425 - val_accuracy: 0.4029\n",
      "Epoch 88/500\n",
      "18/18 [==============================] - 24s 1s/step - loss: 0.0500 - accuracy: 0.9834 - val_loss: 2.7084 - val_accuracy: 0.4101\n",
      "Epoch 89/500\n",
      "18/18 [==============================] - 25s 1s/step - loss: 0.0318 - accuracy: 0.9888 - val_loss: 2.7364 - val_accuracy: 0.4173\n",
      "Epoch 90/500\n",
      "18/18 [==============================] - 24s 1s/step - loss: 0.0623 - accuracy: 0.9720 - val_loss: 2.8157 - val_accuracy: 0.4029\n",
      "Epoch 91/500\n",
      "18/18 [==============================] - 24s 1s/step - loss: 0.0576 - accuracy: 0.9722 - val_loss: 3.0139 - val_accuracy: 0.4101\n",
      "Epoch 92/500\n",
      "18/18 [==============================] - 24s 1s/step - loss: 0.0336 - accuracy: 0.9907 - val_loss: 3.1211 - val_accuracy: 0.4029\n",
      "Epoch 93/500\n",
      "18/18 [==============================] - 28s 2s/step - loss: 0.0556 - accuracy: 0.9732 - val_loss: 2.9118 - val_accuracy: 0.3741\n",
      "Epoch 94/500\n",
      "18/18 [==============================] - 26s 1s/step - loss: 0.0424 - accuracy: 0.9918 - val_loss: 2.7912 - val_accuracy: 0.4245\n",
      "Epoch 95/500\n",
      "18/18 [==============================] - 24s 1s/step - loss: 0.0219 - accuracy: 0.9884 - val_loss: 2.7810 - val_accuracy: 0.4317\n",
      "Epoch 96/500\n",
      "18/18 [==============================] - 26s 1s/step - loss: 0.0293 - accuracy: 0.9935 - val_loss: 2.7440 - val_accuracy: 0.4245\n",
      "Epoch 97/500\n",
      "18/18 [==============================] - 29s 2s/step - loss: 0.0462 - accuracy: 0.9750 - val_loss: 2.8273 - val_accuracy: 0.4029\n",
      "Epoch 98/500\n",
      "18/18 [==============================] - 27s 2s/step - loss: 0.0121 - accuracy: 0.9956 - val_loss: 2.9818 - val_accuracy: 0.3957\n",
      "Epoch 99/500\n",
      "18/18 [==============================] - 29s 2s/step - loss: 0.0326 - accuracy: 0.9822 - val_loss: 2.8513 - val_accuracy: 0.4101\n",
      "Epoch 100/500\n",
      "18/18 [==============================] - 24s 1s/step - loss: 0.0231 - accuracy: 0.9952 - val_loss: 2.7479 - val_accuracy: 0.4245\n",
      "Epoch 101/500\n",
      "18/18 [==============================] - 29s 2s/step - loss: 0.0559 - accuracy: 0.9819 - val_loss: 2.6970 - val_accuracy: 0.4101\n",
      "Epoch 102/500\n",
      "18/18 [==============================] - 29s 2s/step - loss: 0.0201 - accuracy: 0.9941 - val_loss: 2.7709 - val_accuracy: 0.4101\n",
      "Epoch 103/500\n",
      "18/18 [==============================] - 30s 2s/step - loss: 0.0586 - accuracy: 0.9778 - val_loss: 2.6860 - val_accuracy: 0.4029\n",
      "Epoch 104/500\n",
      "18/18 [==============================] - 29s 2s/step - loss: 0.0599 - accuracy: 0.9641 - val_loss: 2.7808 - val_accuracy: 0.4245\n",
      "Epoch 105/500\n",
      "18/18 [==============================] - 27s 2s/step - loss: 0.0288 - accuracy: 0.9879 - val_loss: 2.8339 - val_accuracy: 0.4029\n",
      "Epoch 106/500\n",
      "18/18 [==============================] - 29s 2s/step - loss: 0.0390 - accuracy: 0.9879 - val_loss: 2.9408 - val_accuracy: 0.4029\n",
      "Epoch 107/500\n",
      "18/18 [==============================] - 30s 2s/step - loss: 0.0439 - accuracy: 0.9907 - val_loss: 3.0899 - val_accuracy: 0.3957\n",
      "Epoch 108/500\n",
      "18/18 [==============================] - 32s 2s/step - loss: 0.0230 - accuracy: 0.9945 - val_loss: 3.0984 - val_accuracy: 0.3885\n",
      "Epoch 109/500\n",
      "18/18 [==============================] - 32s 2s/step - loss: 0.0212 - accuracy: 0.9963 - val_loss: 3.0749 - val_accuracy: 0.3813\n",
      "Epoch 110/500\n",
      "18/18 [==============================] - 27s 2s/step - loss: 0.0272 - accuracy: 0.9916 - val_loss: 3.0345 - val_accuracy: 0.3885\n",
      "Epoch 111/500\n",
      "18/18 [==============================] - 24s 1s/step - loss: 0.0149 - accuracy: 0.9982 - val_loss: 2.9800 - val_accuracy: 0.3957\n",
      "Epoch 112/500\n",
      "18/18 [==============================] - 26s 1s/step - loss: 0.0071 - accuracy: 0.9973 - val_loss: 3.0756 - val_accuracy: 0.4029\n",
      "Epoch 113/500\n",
      "18/18 [==============================] - 29s 2s/step - loss: 0.0585 - accuracy: 0.9813 - val_loss: 3.1764 - val_accuracy: 0.3957\n",
      "Epoch 114/500\n",
      "18/18 [==============================] - 28s 2s/step - loss: 0.0280 - accuracy: 0.9858 - val_loss: 3.1224 - val_accuracy: 0.4029\n",
      "Epoch 115/500\n",
      "18/18 [==============================] - 23s 1s/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 3.0809 - val_accuracy: 0.4029\n",
      "Epoch 116/500\n",
      "18/18 [==============================] - 21s 1s/step - loss: 0.0241 - accuracy: 0.9925 - val_loss: 2.9293 - val_accuracy: 0.3957\n",
      "Epoch 117/500\n",
      "18/18 [==============================] - 20s 1s/step - loss: 0.0338 - accuracy: 0.9862 - val_loss: 3.0059 - val_accuracy: 0.3957\n",
      "Epoch 118/500\n",
      "18/18 [==============================] - 20s 1s/step - loss: 0.0143 - accuracy: 1.0000 - val_loss: 3.1524 - val_accuracy: 0.3885\n",
      "Epoch 119/500\n",
      "18/18 [==============================] - 20s 1s/step - loss: 0.0473 - accuracy: 0.9861 - val_loss: 3.2173 - val_accuracy: 0.3813\n",
      "Epoch 120/500\n",
      "18/18 [==============================] - 19s 1s/step - loss: 0.0727 - accuracy: 0.9620 - val_loss: 3.8423 - val_accuracy: 0.3813\n",
      "Epoch 121/500\n",
      "18/18 [==============================] - 20s 1s/step - loss: 0.0544 - accuracy: 0.9686 - val_loss: 3.8618 - val_accuracy: 0.3813\n",
      "Epoch 122/500\n",
      "18/18 [==============================] - 20s 1s/step - loss: 0.0419 - accuracy: 0.9878 - val_loss: 3.2546 - val_accuracy: 0.3813\n",
      "Epoch 123/500\n",
      "18/18 [==============================] - 19s 1s/step - loss: 0.0443 - accuracy: 0.9860 - val_loss: 3.0348 - val_accuracy: 0.4101\n",
      "Epoch 124/500\n",
      "18/18 [==============================] - 20s 1s/step - loss: 0.0341 - accuracy: 0.9883 - val_loss: 2.9563 - val_accuracy: 0.3957\n",
      "Epoch 125/500\n",
      "18/18 [==============================] - 21s 1s/step - loss: 0.0162 - accuracy: 0.9938 - val_loss: 3.0310 - val_accuracy: 0.4029\n",
      "Epoch 126/500\n",
      "18/18 [==============================] - 21s 1s/step - loss: 0.0212 - accuracy: 0.9904 - val_loss: 2.9897 - val_accuracy: 0.3813\n",
      "Epoch 127/500\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.0285 - accuracy: 0.9910 - val_loss: 2.9442 - val_accuracy: 0.3957\n",
      "Epoch 128/500\n",
      "18/18 [==============================] - 20s 1s/step - loss: 0.0210 - accuracy: 0.9961 - val_loss: 2.9977 - val_accuracy: 0.4029\n",
      "Epoch 129/500\n",
      "18/18 [==============================] - 19s 1s/step - loss: 0.0058 - accuracy: 0.9971 - val_loss: 3.1017 - val_accuracy: 0.3885\n",
      "Epoch 130/500\n",
      "18/18 [==============================] - 19s 1s/step - loss: 0.0553 - accuracy: 0.9750 - val_loss: 3.0612 - val_accuracy: 0.4029\n",
      "Epoch 131/500\n",
      "18/18 [==============================] - 20s 1s/step - loss: 0.0555 - accuracy: 0.9713 - val_loss: 3.0532 - val_accuracy: 0.4029\n",
      "Epoch 132/500\n",
      "18/18 [==============================] - 19s 1s/step - loss: 0.0190 - accuracy: 0.9968 - val_loss: 3.0008 - val_accuracy: 0.4317\n",
      "Epoch 133/500\n",
      "18/18 [==============================] - 19s 1s/step - loss: 0.0322 - accuracy: 0.9854 - val_loss: 2.9479 - val_accuracy: 0.4317\n",
      "Epoch 134/500\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.0603 - accuracy: 0.9757 - val_loss: 2.8387 - val_accuracy: 0.4173\n",
      "Epoch 135/500\n",
      "18/18 [==============================] - 24s 1s/step - loss: 0.0557 - accuracy: 0.9711 - val_loss: 2.8151 - val_accuracy: 0.4245\n",
      "Epoch 136/500\n",
      "18/18 [==============================] - 20s 1s/step - loss: 0.0073 - accuracy: 0.9987 - val_loss: 2.8869 - val_accuracy: 0.4317\n",
      "Epoch 137/500\n",
      "18/18 [==============================] - 20s 1s/step - loss: 0.0232 - accuracy: 0.9866 - val_loss: 2.9753 - val_accuracy: 0.3957\n",
      "Epoch 138/500\n",
      "18/18 [==============================] - 20s 1s/step - loss: 0.0272 - accuracy: 0.9913 - val_loss: 3.2143 - val_accuracy: 0.3741\n",
      "Epoch 139/500\n",
      "18/18 [==============================] - 20s 1s/step - loss: 0.0191 - accuracy: 0.9922 - val_loss: 3.0844 - val_accuracy: 0.4029\n",
      "Epoch 140/500\n",
      "18/18 [==============================] - 28s 2s/step - loss: 0.0245 - accuracy: 0.9892 - val_loss: 3.0800 - val_accuracy: 0.4029\n",
      "Epoch 141/500\n",
      "18/18 [==============================] - 25s 1s/step - loss: 0.0645 - accuracy: 0.9895 - val_loss: 3.0724 - val_accuracy: 0.4029\n",
      "Epoch 142/500\n",
      "18/18 [==============================] - 24s 1s/step - loss: 0.0065 - accuracy: 0.9990 - val_loss: 3.0129 - val_accuracy: 0.4101\n",
      "Epoch 143/500\n",
      "18/18 [==============================] - 25s 1s/step - loss: 0.0370 - accuracy: 0.9873 - val_loss: 3.0097 - val_accuracy: 0.4245\n",
      "Epoch 144/500\n",
      "18/18 [==============================] - 21s 1s/step - loss: 0.0170 - accuracy: 0.9915 - val_loss: 3.0588 - val_accuracy: 0.4029\n",
      "Epoch 145/500\n",
      "18/18 [==============================] - 29s 2s/step - loss: 0.0082 - accuracy: 0.9975 - val_loss: 3.0889 - val_accuracy: 0.4029\n",
      "Epoch 146/500\n",
      "18/18 [==============================] - 26s 1s/step - loss: 0.0540 - accuracy: 0.9817 - val_loss: 3.0038 - val_accuracy: 0.4173\n",
      "Epoch 147/500\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.0320 - accuracy: 0.9862 - val_loss: 3.0907 - val_accuracy: 0.3813\n",
      "Epoch 148/500\n",
      "18/18 [==============================] - 26s 1s/step - loss: 0.0440 - accuracy: 0.9869 - val_loss: 3.1944 - val_accuracy: 0.3957\n",
      "Epoch 149/500\n",
      "18/18 [==============================] - 23s 1s/step - loss: 0.0333 - accuracy: 0.9835 - val_loss: 2.9835 - val_accuracy: 0.4101\n",
      "Epoch 150/500\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.0099 - accuracy: 0.9943 - val_loss: 3.0154 - val_accuracy: 0.3885\n",
      "Epoch 151/500\n",
      "18/18 [==============================] - 20s 1s/step - loss: 0.0347 - accuracy: 0.9842 - val_loss: 3.2659 - val_accuracy: 0.3957\n",
      "Epoch 152/500\n",
      "18/18 [==============================] - 24s 1s/step - loss: 0.0165 - accuracy: 0.9992 - val_loss: 3.3076 - val_accuracy: 0.4029\n",
      "Epoch 153/500\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.0143 - accuracy: 0.9980 - val_loss: 3.3843 - val_accuracy: 0.4173\n",
      "Epoch 154/500\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.0147 - accuracy: 0.9946 - val_loss: 3.3290 - val_accuracy: 0.4101\n",
      "Epoch 155/500\n",
      "18/18 [==============================] - 21s 1s/step - loss: 0.0349 - accuracy: 0.9808 - val_loss: 3.3299 - val_accuracy: 0.4317\n",
      "Epoch 156/500\n",
      "18/18 [==============================] - 20s 1s/step - loss: 0.0318 - accuracy: 0.9831 - val_loss: 3.5152 - val_accuracy: 0.4029\n",
      "Epoch 157/500\n",
      "18/18 [==============================] - 20s 1s/step - loss: 0.0282 - accuracy: 0.9915 - val_loss: 3.5047 - val_accuracy: 0.4029\n",
      "Epoch 158/500\n",
      "18/18 [==============================] - 20s 1s/step - loss: 0.0465 - accuracy: 0.9826 - val_loss: 3.3193 - val_accuracy: 0.4317\n",
      "Epoch 159/500\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.0510 - accuracy: 0.9860 - val_loss: 3.1267 - val_accuracy: 0.4245\n",
      "Epoch 160/500\n",
      "18/18 [==============================] - 20s 1s/step - loss: 0.0195 - accuracy: 0.9909 - val_loss: 3.0870 - val_accuracy: 0.4317\n",
      "Epoch 161/500\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.0046 - accuracy: 0.9990 - val_loss: 3.0645 - val_accuracy: 0.4245\n",
      "Epoch 162/500\n",
      "18/18 [==============================] - 19s 1s/step - loss: 0.0316 - accuracy: 0.9880 - val_loss: 2.9911 - val_accuracy: 0.4317\n",
      "Epoch 163/500\n",
      "18/18 [==============================] - 20s 1s/step - loss: 0.0146 - accuracy: 0.9943 - val_loss: 3.2367 - val_accuracy: 0.4101\n",
      "Epoch 164/500\n",
      "18/18 [==============================] - 19s 1s/step - loss: 0.0129 - accuracy: 0.9919 - val_loss: 3.3921 - val_accuracy: 0.4101\n",
      "Epoch 165/500\n",
      "18/18 [==============================] - 19s 1s/step - loss: 0.0630 - accuracy: 0.9732 - val_loss: 3.1219 - val_accuracy: 0.4388\n",
      "Epoch 166/500\n",
      "18/18 [==============================] - 19s 1s/step - loss: 0.0142 - accuracy: 0.9979 - val_loss: 3.0117 - val_accuracy: 0.4460\n",
      "Epoch 167/500\n",
      "18/18 [==============================] - 19s 1s/step - loss: 0.0640 - accuracy: 0.9774 - val_loss: 3.1963 - val_accuracy: 0.4388\n",
      "Epoch 168/500\n",
      "18/18 [==============================] - 19s 1s/step - loss: 0.0314 - accuracy: 0.9915 - val_loss: 2.9264 - val_accuracy: 0.4317\n",
      "Epoch 169/500\n",
      "18/18 [==============================] - 19s 1s/step - loss: 0.0337 - accuracy: 0.9867 - val_loss: 2.8282 - val_accuracy: 0.4317\n",
      "Epoch 170/500\n",
      "18/18 [==============================] - 20s 1s/step - loss: 0.0069 - accuracy: 0.9992 - val_loss: 2.9058 - val_accuracy: 0.4317\n",
      "Epoch 171/500\n",
      "18/18 [==============================] - 19s 1s/step - loss: 0.0199 - accuracy: 0.9929 - val_loss: 3.0071 - val_accuracy: 0.4101\n",
      "Epoch 172/500\n",
      "18/18 [==============================] - 19s 1s/step - loss: 0.0211 - accuracy: 0.9940 - val_loss: 2.8622 - val_accuracy: 0.4101\n",
      "Epoch 173/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 19s 1s/step - loss: 0.0221 - accuracy: 0.9964 - val_loss: 2.8637 - val_accuracy: 0.4173\n",
      "Epoch 174/500\n",
      "18/18 [==============================] - 19s 1s/step - loss: 0.0085 - accuracy: 0.9988 - val_loss: 2.8352 - val_accuracy: 0.4101\n",
      "Epoch 175/500\n",
      "18/18 [==============================] - 19s 1s/step - loss: 0.0125 - accuracy: 0.9969 - val_loss: 2.8214 - val_accuracy: 0.4388\n",
      "Epoch 176/500\n",
      "18/18 [==============================] - 19s 1s/step - loss: 0.0212 - accuracy: 0.9959 - val_loss: 2.8580 - val_accuracy: 0.4460\n",
      "Epoch 177/500\n",
      "18/18 [==============================] - 19s 1s/step - loss: 0.0370 - accuracy: 0.9780 - val_loss: 2.7278 - val_accuracy: 0.4388\n",
      "Epoch 178/500\n",
      "18/18 [==============================] - 20s 1s/step - loss: 0.0233 - accuracy: 0.9958 - val_loss: 2.6916 - val_accuracy: 0.4388\n",
      "Epoch 179/500\n",
      "18/18 [==============================] - 20s 1s/step - loss: 0.0152 - accuracy: 0.9996 - val_loss: 2.8137 - val_accuracy: 0.4388\n",
      "Epoch 180/500\n",
      "18/18 [==============================] - 19s 1s/step - loss: 0.0315 - accuracy: 0.9930 - val_loss: 2.9225 - val_accuracy: 0.4317\n",
      "Epoch 181/500\n",
      "18/18 [==============================] - 20s 1s/step - loss: 0.0286 - accuracy: 0.9800 - val_loss: 3.0571 - val_accuracy: 0.4532\n",
      "Epoch 182/500\n",
      "18/18 [==============================] - 21s 1s/step - loss: 0.0119 - accuracy: 0.9963 - val_loss: 3.0681 - val_accuracy: 0.4173\n",
      "Epoch 183/500\n",
      "18/18 [==============================] - 21s 1s/step - loss: 0.0182 - accuracy: 0.9936 - val_loss: 3.1376 - val_accuracy: 0.4532\n",
      "Epoch 184/500\n",
      "18/18 [==============================] - 21s 1s/step - loss: 0.0182 - accuracy: 0.9864 - val_loss: 3.1090 - val_accuracy: 0.4604\n",
      "Epoch 185/500\n",
      "18/18 [==============================] - 20s 1s/step - loss: 0.0215 - accuracy: 0.9934 - val_loss: 3.0941 - val_accuracy: 0.4460\n",
      "Epoch 186/500\n",
      "18/18 [==============================] - 19s 1s/step - loss: 0.0161 - accuracy: 0.9909 - val_loss: 3.1432 - val_accuracy: 0.4173\n",
      "Epoch 187/500\n",
      "18/18 [==============================] - 19s 1s/step - loss: 0.0220 - accuracy: 0.9951 - val_loss: 3.1182 - val_accuracy: 0.4173\n",
      "Epoch 188/500\n",
      "18/18 [==============================] - 19s 1s/step - loss: 0.0098 - accuracy: 0.9963 - val_loss: 3.1632 - val_accuracy: 0.4173\n",
      "Epoch 189/500\n",
      "18/18 [==============================] - 19s 1s/step - loss: 0.0121 - accuracy: 0.9940 - val_loss: 3.2233 - val_accuracy: 0.4317\n",
      "Epoch 190/500\n",
      "18/18 [==============================] - 19s 1s/step - loss: 0.0223 - accuracy: 0.9895 - val_loss: 3.3109 - val_accuracy: 0.4532\n",
      "Epoch 191/500\n",
      "18/18 [==============================] - 19s 1s/step - loss: 0.0139 - accuracy: 0.9868 - val_loss: 3.0705 - val_accuracy: 0.4748\n",
      "Epoch 192/500\n",
      "18/18 [==============================] - 19s 1s/step - loss: 0.0040 - accuracy: 0.9990 - val_loss: 3.0351 - val_accuracy: 0.4604\n",
      "Epoch 193/500\n",
      "18/18 [==============================] - 19s 1s/step - loss: 0.0117 - accuracy: 0.9958 - val_loss: 3.0788 - val_accuracy: 0.4676\n",
      "Epoch 194/500\n",
      "18/18 [==============================] - 19s 1s/step - loss: 0.0224 - accuracy: 0.9935 - val_loss: 2.9344 - val_accuracy: 0.4173\n",
      "Epoch 195/500\n",
      "18/18 [==============================] - 19s 1s/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 2.9564 - val_accuracy: 0.4173\n",
      "Epoch 196/500\n",
      "18/18 [==============================] - 19s 1s/step - loss: 0.0196 - accuracy: 0.9883 - val_loss: 2.9823 - val_accuracy: 0.4245\n",
      "Epoch 197/500\n",
      "18/18 [==============================] - 19s 1s/step - loss: 0.0125 - accuracy: 0.9954 - val_loss: 3.0652 - val_accuracy: 0.4388\n",
      "Epoch 198/500\n",
      "18/18 [==============================] - 19s 1s/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 3.0919 - val_accuracy: 0.4532\n",
      "Epoch 199/500\n",
      "18/18 [==============================] - 19s 1s/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 3.0693 - val_accuracy: 0.4604\n",
      "Epoch 200/500\n",
      "18/18 [==============================] - 19s 1s/step - loss: 0.0257 - accuracy: 0.9893 - val_loss: 3.1313 - val_accuracy: 0.4317\n",
      "Epoch 201/500\n",
      "18/18 [==============================] - 19s 1s/step - loss: 0.0113 - accuracy: 0.9943 - val_loss: 3.2187 - val_accuracy: 0.4173\n",
      "Epoch 202/500\n",
      "18/18 [==============================] - 19s 1s/step - loss: 0.0162 - accuracy: 1.0000 - val_loss: 3.2561 - val_accuracy: 0.4101\n",
      "Epoch 203/500\n",
      "18/18 [==============================] - 19s 1s/step - loss: 0.0208 - accuracy: 0.9910 - val_loss: 3.2341 - val_accuracy: 0.4245\n",
      "Epoch 204/500\n",
      "18/18 [==============================] - 19s 1s/step - loss: 0.0245 - accuracy: 0.9932 - val_loss: 3.2033 - val_accuracy: 0.4532\n",
      "Epoch 205/500\n",
      "18/18 [==============================] - 19s 1s/step - loss: 0.0075 - accuracy: 0.9961 - val_loss: 3.1990 - val_accuracy: 0.4604\n",
      "Epoch 206/500\n",
      "18/18 [==============================] - 19s 1s/step - loss: 0.0079 - accuracy: 0.9961 - val_loss: 3.2530 - val_accuracy: 0.4317\n",
      "Epoch 207/500\n",
      "18/18 [==============================] - 19s 1s/step - loss: 0.0119 - accuracy: 0.9978 - val_loss: 3.2499 - val_accuracy: 0.4101\n",
      "Epoch 208/500\n",
      "18/18 [==============================] - 19s 1s/step - loss: 0.0198 - accuracy: 0.9931 - val_loss: 3.2308 - val_accuracy: 0.4460\n",
      "Epoch 209/500\n",
      "18/18 [==============================] - 19s 1s/step - loss: 0.0191 - accuracy: 0.9906 - val_loss: 3.2673 - val_accuracy: 0.4173\n",
      "Epoch 210/500\n",
      "18/18 [==============================] - 19s 1s/step - loss: 0.0266 - accuracy: 0.9846 - val_loss: 3.3330 - val_accuracy: 0.4317\n",
      "Epoch 211/500\n",
      "18/18 [==============================] - 20s 1s/step - loss: 0.0124 - accuracy: 0.9942 - val_loss: 3.2010 - val_accuracy: 0.4388\n",
      "Epoch 212/500\n",
      "18/18 [==============================] - 20s 1s/step - loss: 0.0217 - accuracy: 0.9990 - val_loss: 3.2977 - val_accuracy: 0.4029\n",
      "Epoch 213/500\n",
      "18/18 [==============================] - 23s 1s/step - loss: 0.0152 - accuracy: 0.9980 - val_loss: 3.3592 - val_accuracy: 0.4101\n",
      "Epoch 214/500\n",
      "18/18 [==============================] - 21s 1s/step - loss: 0.0057 - accuracy: 0.9982 - val_loss: 3.5119 - val_accuracy: 0.3885\n",
      "Epoch 215/500\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.0102 - accuracy: 0.9957 - val_loss: 3.6366 - val_accuracy: 0.3741\n",
      "Epoch 216/500\n",
      "18/18 [==============================] - 21s 1s/step - loss: 0.0161 - accuracy: 0.9924 - val_loss: 3.5458 - val_accuracy: 0.3813\n",
      "Epoch 217/500\n",
      "18/18 [==============================] - 20s 1s/step - loss: 0.0101 - accuracy: 0.9964 - val_loss: 3.5021 - val_accuracy: 0.3813\n",
      "Epoch 218/500\n",
      "18/18 [==============================] - 20s 1s/step - loss: 0.0039 - accuracy: 0.9992 - val_loss: 3.4811 - val_accuracy: 0.3741\n",
      "Epoch 219/500\n",
      "18/18 [==============================] - 20s 1s/step - loss: 0.0126 - accuracy: 0.9982 - val_loss: 3.4479 - val_accuracy: 0.3741\n",
      "Epoch 220/500\n",
      "18/18 [==============================] - 20s 1s/step - loss: 0.0769 - accuracy: 0.9828 - val_loss: 3.4177 - val_accuracy: 0.3957\n",
      "Epoch 221/500\n",
      "18/18 [==============================] - 20s 1s/step - loss: 0.0107 - accuracy: 0.9951 - val_loss: 3.5066 - val_accuracy: 0.3957\n",
      "Epoch 222/500\n",
      "18/18 [==============================] - 20s 1s/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 3.5314 - val_accuracy: 0.3957\n",
      "Epoch 223/500\n",
      "18/18 [==============================] - 20s 1s/step - loss: 0.0566 - accuracy: 0.9873 - val_loss: 3.4838 - val_accuracy: 0.3885\n",
      "Epoch 224/500\n",
      "18/18 [==============================] - 20s 1s/step - loss: 0.0117 - accuracy: 0.9962 - val_loss: 3.5217 - val_accuracy: 0.4029\n",
      "Epoch 225/500\n",
      "18/18 [==============================] - 20s 1s/step - loss: 0.0533 - accuracy: 0.9770 - val_loss: 3.8938 - val_accuracy: 0.3669\n",
      "Epoch 226/500\n",
      "18/18 [==============================] - 20s 1s/step - loss: 0.0678 - accuracy: 0.9858 - val_loss: 4.0594 - val_accuracy: 0.3669\n",
      "Epoch 227/500\n",
      "18/18 [==============================] - 20s 1s/step - loss: 0.0447 - accuracy: 0.9881 - val_loss: 3.9463 - val_accuracy: 0.3669\n",
      "Epoch 228/500\n",
      "18/18 [==============================] - 20s 1s/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 4.0201 - val_accuracy: 0.3813\n",
      "Epoch 229/500\n",
      "18/18 [==============================] - 20s 1s/step - loss: 0.0074 - accuracy: 0.9986 - val_loss: 4.1188 - val_accuracy: 0.3885\n",
      "Epoch 230/500\n",
      "18/18 [==============================] - 20s 1s/step - loss: 0.0315 - accuracy: 0.9888 - val_loss: 3.8355 - val_accuracy: 0.3813\n",
      "Epoch 231/500\n",
      "18/18 [==============================] - 20s 1s/step - loss: 0.0121 - accuracy: 0.9971 - val_loss: 3.7602 - val_accuracy: 0.3957\n",
      "Epoch 232/500\n",
      "18/18 [==============================] - 20s 1s/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 3.8274 - val_accuracy: 0.3957\n",
      "Epoch 233/500\n",
      "18/18 [==============================] - 20s 1s/step - loss: 0.0274 - accuracy: 0.9889 - val_loss: 3.6191 - val_accuracy: 0.4029\n",
      "Epoch 234/500\n",
      "18/18 [==============================] - 20s 1s/step - loss: 0.0271 - accuracy: 0.9855 - val_loss: 3.3133 - val_accuracy: 0.4245\n",
      "Epoch 235/500\n",
      "18/18 [==============================] - 20s 1s/step - loss: 0.0222 - accuracy: 0.9926 - val_loss: 3.2126 - val_accuracy: 0.4388\n",
      "Epoch 236/500\n",
      "18/18 [==============================] - 20s 1s/step - loss: 0.0109 - accuracy: 0.9956 - val_loss: 3.3292 - val_accuracy: 0.3885\n",
      "Epoch 237/500\n",
      "18/18 [==============================] - 20s 1s/step - loss: 0.0150 - accuracy: 0.9956 - val_loss: 3.3521 - val_accuracy: 0.4029\n",
      "Epoch 238/500\n",
      "18/18 [==============================] - 21s 1s/step - loss: 0.0463 - accuracy: 0.9806 - val_loss: 3.2172 - val_accuracy: 0.4173\n",
      "Epoch 239/500\n",
      "18/18 [==============================] - 21s 1s/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 3.2093 - val_accuracy: 0.4101\n",
      "Epoch 240/500\n",
      "18/18 [==============================] - 20s 1s/step - loss: 0.0292 - accuracy: 0.9910 - val_loss: 3.1498 - val_accuracy: 0.4029\n",
      "Epoch 241/500\n",
      "18/18 [==============================] - 20s 1s/step - loss: 0.0099 - accuracy: 0.9968 - val_loss: 3.2032 - val_accuracy: 0.3885\n",
      "Epoch 242/500\n",
      "18/18 [==============================] - 21s 1s/step - loss: 0.0233 - accuracy: 0.9871 - val_loss: 3.2798 - val_accuracy: 0.3957\n",
      "Epoch 243/500\n",
      "18/18 [==============================] - 24s 1s/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 3.3306 - val_accuracy: 0.3957\n",
      "Epoch 244/500\n",
      "18/18 [==============================] - 21s 1s/step - loss: 0.0097 - accuracy: 0.9982 - val_loss: 3.3145 - val_accuracy: 0.4101\n",
      "Epoch 245/500\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.0104 - accuracy: 0.9945 - val_loss: 3.3805 - val_accuracy: 0.4029\n",
      "Epoch 246/500\n",
      "18/18 [==============================] - 21s 1s/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 3.5728 - val_accuracy: 0.3885\n",
      "Epoch 247/500\n",
      "18/18 [==============================] - 19s 1s/step - loss: 0.0071 - accuracy: 0.9964 - val_loss: 3.5370 - val_accuracy: 0.3885\n",
      "Epoch 248/500\n",
      "18/18 [==============================] - 20s 1s/step - loss: 0.0132 - accuracy: 0.9868 - val_loss: 3.5844 - val_accuracy: 0.4029\n",
      "Epoch 249/500\n",
      "18/18 [==============================] - 20s 1s/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 3.6192 - val_accuracy: 0.3957\n",
      "Epoch 250/500\n",
      "18/18 [==============================] - 20s 1s/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 3.6693 - val_accuracy: 0.3957\n",
      "Epoch 251/500\n",
      "18/18 [==============================] - 20s 1s/step - loss: 0.0399 - accuracy: 0.9915 - val_loss: 3.6463 - val_accuracy: 0.3957\n",
      "Epoch 252/500\n",
      "18/18 [==============================] - 20s 1s/step - loss: 0.0147 - accuracy: 0.9954 - val_loss: 3.8441 - val_accuracy: 0.3813\n",
      "Epoch 253/500\n",
      "18/18 [==============================] - 20s 1s/step - loss: 0.0148 - accuracy: 0.9956 - val_loss: 3.6680 - val_accuracy: 0.3885\n",
      "Epoch 254/500\n",
      "18/18 [==============================] - 20s 1s/step - loss: 0.0133 - accuracy: 0.9957 - val_loss: 3.7062 - val_accuracy: 0.3813\n",
      "Epoch 255/500\n",
      "18/18 [==============================] - 20s 1s/step - loss: 0.0077 - accuracy: 0.9985 - val_loss: 3.9650 - val_accuracy: 0.3885\n",
      "Epoch 256/500\n",
      "18/18 [==============================] - 19s 1s/step - loss: 0.0123 - accuracy: 0.9992 - val_loss: 3.9976 - val_accuracy: 0.3741\n",
      "Epoch 257/500\n",
      "18/18 [==============================] - 20s 1s/step - loss: 0.0113 - accuracy: 0.9916 - val_loss: 4.0797 - val_accuracy: 0.3813\n",
      "Epoch 258/500\n",
      "18/18 [==============================] - 20s 1s/step - loss: 0.0209 - accuracy: 0.9939 - val_loss: 4.1236 - val_accuracy: 0.3885\n",
      "Epoch 259/500\n",
      "18/18 [==============================] - 20s 1s/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 4.1216 - val_accuracy: 0.3813\n",
      "Epoch 260/500\n",
      "18/18 [==============================] - 20s 1s/step - loss: 0.0118 - accuracy: 0.9957 - val_loss: 4.0218 - val_accuracy: 0.3597\n",
      "Epoch 261/500\n",
      "18/18 [==============================] - 20s 1s/step - loss: 0.0196 - accuracy: 0.9951 - val_loss: 3.8007 - val_accuracy: 0.3741\n",
      "Epoch 262/500\n",
      "18/18 [==============================] - 19s 1s/step - loss: 0.0217 - accuracy: 0.9926 - val_loss: 3.6940 - val_accuracy: 0.4029\n",
      "Epoch 263/500\n",
      "18/18 [==============================] - 19s 1s/step - loss: 0.0442 - accuracy: 0.9839 - val_loss: 3.7181 - val_accuracy: 0.3957\n",
      "Epoch 264/500\n",
      "18/18 [==============================] - 18s 1000ms/step - loss: 0.0136 - accuracy: 1.0000 - val_loss: 3.8280 - val_accuracy: 0.4101\n",
      "Epoch 265/500\n",
      "18/18 [==============================] - 18s 998ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 3.8641 - val_accuracy: 0.4245\n",
      "Epoch 266/500\n",
      "18/18 [==============================] - 17s 976ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 3.8838 - val_accuracy: 0.4029\n",
      "Epoch 267/500\n",
      "18/18 [==============================] - 18s 996ms/step - loss: 0.0068 - accuracy: 0.9972 - val_loss: 3.8244 - val_accuracy: 0.4173\n",
      "Epoch 268/500\n",
      "18/18 [==============================] - 18s 983ms/step - loss: 0.0207 - accuracy: 0.9894 - val_loss: 3.6850 - val_accuracy: 0.4173\n",
      "Epoch 269/500\n",
      "18/18 [==============================] - 18s 990ms/step - loss: 0.0065 - accuracy: 0.9988 - val_loss: 3.5674 - val_accuracy: 0.4245\n",
      "Epoch 270/500\n",
      "18/18 [==============================] - 18s 986ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 3.5406 - val_accuracy: 0.4317\n",
      "Epoch 271/500\n",
      "18/18 [==============================] - 18s 1s/step - loss: 0.0038 - accuracy: 0.9982 - val_loss: 3.5135 - val_accuracy: 0.4317\n",
      "Epoch 272/500\n",
      "18/18 [==============================] - 17s 994ms/step - loss: 0.0026 - accuracy: 0.9996 - val_loss: 3.4752 - val_accuracy: 0.4245\n",
      "Epoch 273/500\n",
      "18/18 [==============================] - 19s 1s/step - loss: 0.0128 - accuracy: 0.9882 - val_loss: 3.4909 - val_accuracy: 0.4388\n",
      "Epoch 274/500\n",
      "18/18 [==============================] - 18s 1s/step - loss: 0.0161 - accuracy: 0.9968 - val_loss: 3.5746 - val_accuracy: 0.4101\n",
      "Epoch 275/500\n",
      "18/18 [==============================] - 20s 1s/step - loss: 0.0049 - accuracy: 0.9996 - val_loss: 3.6196 - val_accuracy: 0.4101\n",
      "Epoch 276/500\n",
      "18/18 [==============================] - 19s 1s/step - loss: 0.0616 - accuracy: 0.9942 - val_loss: 3.6878 - val_accuracy: 0.4101\n",
      "Epoch 277/500\n",
      "18/18 [==============================] - 18s 980ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 3.6755 - val_accuracy: 0.4029\n",
      "Epoch 278/500\n",
      "18/18 [==============================] - 17s 965ms/step - loss: 0.0325 - accuracy: 0.9848 - val_loss: 3.6889 - val_accuracy: 0.3885\n",
      "Epoch 279/500\n",
      "18/18 [==============================] - 17s 962ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 3.7184 - val_accuracy: 0.3957\n",
      "Epoch 280/500\n",
      "18/18 [==============================] - 17s 971ms/step - loss: 0.0161 - accuracy: 0.9962 - val_loss: 3.8838 - val_accuracy: 0.3885\n",
      "Epoch 281/500\n",
      "18/18 [==============================] - 17s 959ms/step - loss: 0.0122 - accuracy: 0.9931 - val_loss: 3.9056 - val_accuracy: 0.4101\n",
      "Epoch 282/500\n",
      "18/18 [==============================] - 18s 980ms/step - loss: 0.0240 - accuracy: 0.9847 - val_loss: 3.8234 - val_accuracy: 0.3957\n",
      "Epoch 283/500\n",
      "18/18 [==============================] - 17s 958ms/step - loss: 0.0502 - accuracy: 0.9765 - val_loss: 4.1492 - val_accuracy: 0.3885\n",
      "Epoch 284/500\n",
      "18/18 [==============================] - 18s 979ms/step - loss: 0.0085 - accuracy: 0.9960 - val_loss: 4.0805 - val_accuracy: 0.3957\n",
      "Epoch 285/500\n",
      "18/18 [==============================] - 17s 975ms/step - loss: 0.0144 - accuracy: 0.9982 - val_loss: 3.8886 - val_accuracy: 0.4173\n",
      "Epoch 286/500\n",
      "18/18 [==============================] - 18s 1s/step - loss: 0.0172 - accuracy: 0.9946 - val_loss: 3.8830 - val_accuracy: 0.3885\n",
      "Epoch 287/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 19s 1s/step - loss: 0.0079 - accuracy: 0.9972 - val_loss: 3.8271 - val_accuracy: 0.3885\n",
      "Epoch 288/500\n",
      "18/18 [==============================] - 18s 978ms/step - loss: 0.0112 - accuracy: 0.9990 - val_loss: 3.9536 - val_accuracy: 0.3885\n",
      "Epoch 289/500\n",
      "18/18 [==============================] - 17s 961ms/step - loss: 0.0033 - accuracy: 0.9987 - val_loss: 3.9611 - val_accuracy: 0.3957\n",
      "Epoch 290/500\n",
      "18/18 [==============================] - 18s 975ms/step - loss: 0.0334 - accuracy: 0.9896 - val_loss: 3.3904 - val_accuracy: 0.4173\n",
      "Epoch 291/500\n",
      "18/18 [==============================] - 17s 963ms/step - loss: 0.0152 - accuracy: 0.9949 - val_loss: 3.4409 - val_accuracy: 0.3885\n",
      "Epoch 292/500\n",
      "18/18 [==============================] - 18s 974ms/step - loss: 0.0178 - accuracy: 0.9918 - val_loss: 3.4041 - val_accuracy: 0.4029\n",
      "Epoch 293/500\n",
      "18/18 [==============================] - 18s 972ms/step - loss: 0.0120 - accuracy: 0.9942 - val_loss: 3.4111 - val_accuracy: 0.3885\n",
      "Epoch 294/500\n",
      "18/18 [==============================] - 17s 962ms/step - loss: 0.0129 - accuracy: 0.9959 - val_loss: 3.3243 - val_accuracy: 0.4101\n",
      "Epoch 295/500\n",
      "18/18 [==============================] - 18s 981ms/step - loss: 0.0364 - accuracy: 0.9801 - val_loss: 3.4678 - val_accuracy: 0.3957\n",
      "Epoch 296/500\n",
      "18/18 [==============================] - 18s 975ms/step - loss: 0.0173 - accuracy: 0.9918 - val_loss: 3.5421 - val_accuracy: 0.4029\n",
      "Epoch 297/500\n",
      "18/18 [==============================] - 18s 1s/step - loss: 0.0347 - accuracy: 0.9896 - val_loss: 3.6897 - val_accuracy: 0.3669\n",
      "Epoch 298/500\n",
      "18/18 [==============================] - 19s 1s/step - loss: 0.0236 - accuracy: 0.9946 - val_loss: 3.8653 - val_accuracy: 0.3741\n",
      "Epoch 299/500\n",
      "18/18 [==============================] - 21s 1s/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 3.9063 - val_accuracy: 0.3813\n",
      "Epoch 300/500\n",
      "18/18 [==============================] - 20s 1s/step - loss: 0.0155 - accuracy: 0.9930 - val_loss: 4.0116 - val_accuracy: 0.3957\n",
      "Epoch 301/500\n",
      "18/18 [==============================] - 18s 1s/step - loss: 0.0373 - accuracy: 0.9815 - val_loss: 3.8702 - val_accuracy: 0.3957\n",
      "Epoch 302/500\n",
      "18/18 [==============================] - 18s 970ms/step - loss: 0.0185 - accuracy: 0.9964 - val_loss: 3.8897 - val_accuracy: 0.3813\n",
      "Epoch 303/500\n",
      "18/18 [==============================] - 18s 967ms/step - loss: 0.0142 - accuracy: 0.9948 - val_loss: 3.9213 - val_accuracy: 0.3885\n",
      "Epoch 304/500\n",
      "18/18 [==============================] - 17s 973ms/step - loss: 0.0100 - accuracy: 0.9956 - val_loss: 3.9144 - val_accuracy: 0.3813\n",
      "Epoch 305/500\n",
      "18/18 [==============================] - 18s 979ms/step - loss: 0.0207 - accuracy: 0.9924 - val_loss: 3.9523 - val_accuracy: 0.4029\n",
      "Epoch 306/500\n",
      "18/18 [==============================] - 19s 1s/step - loss: 0.0271 - accuracy: 0.9946 - val_loss: 3.8991 - val_accuracy: 0.3813\n",
      "Epoch 307/500\n",
      "18/18 [==============================] - 20s 1s/step - loss: 0.0225 - accuracy: 0.9815 - val_loss: 3.7815 - val_accuracy: 0.3813\n",
      "Epoch 308/500\n",
      "18/18 [==============================] - 19s 1s/step - loss: 0.0362 - accuracy: 0.9915 - val_loss: 3.7422 - val_accuracy: 0.3813\n",
      "Epoch 309/500\n",
      "18/18 [==============================] - 19s 1s/step - loss: 0.0061 - accuracy: 0.9990 - val_loss: 3.7054 - val_accuracy: 0.3813\n",
      "Epoch 310/500\n",
      "18/18 [==============================] - 18s 981ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 3.8067 - val_accuracy: 0.3813\n",
      "Epoch 311/500\n",
      "18/18 [==============================] - 18s 1s/step - loss: 0.0067 - accuracy: 0.9964 - val_loss: 3.8343 - val_accuracy: 0.3813\n",
      "Epoch 312/500\n",
      "18/18 [==============================] - 17s 967ms/step - loss: 0.0223 - accuracy: 0.9967 - val_loss: 3.8366 - val_accuracy: 0.3885\n",
      "Epoch 313/500\n",
      "18/18 [==============================] - 17s 965ms/step - loss: 0.0287 - accuracy: 0.9901 - val_loss: 3.8777 - val_accuracy: 0.3957\n",
      "Epoch 314/500\n",
      "18/18 [==============================] - 18s 990ms/step - loss: 0.0102 - accuracy: 0.9951 - val_loss: 3.7129 - val_accuracy: 0.3885\n",
      "Epoch 315/500\n",
      "18/18 [==============================] - 18s 985ms/step - loss: 0.0160 - accuracy: 0.9929 - val_loss: 3.7786 - val_accuracy: 0.3957\n",
      "Epoch 316/500\n",
      "18/18 [==============================] - 18s 979ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 3.8009 - val_accuracy: 0.3885\n",
      "Epoch 317/500\n",
      "18/18 [==============================] - 18s 990ms/step - loss: 0.0139 - accuracy: 0.9930 - val_loss: 3.7886 - val_accuracy: 0.4101\n",
      "Epoch 318/500\n",
      "18/18 [==============================] - 18s 968ms/step - loss: 0.0038 - accuracy: 0.9996 - val_loss: 3.7564 - val_accuracy: 0.3957\n",
      "Epoch 319/500\n",
      "18/18 [==============================] - 17s 962ms/step - loss: 0.0061 - accuracy: 0.9979 - val_loss: 3.7478 - val_accuracy: 0.3957\n",
      "Epoch 320/500\n",
      "18/18 [==============================] - 18s 980ms/step - loss: 0.0251 - accuracy: 0.9926 - val_loss: 3.6937 - val_accuracy: 0.3813\n",
      "Epoch 321/500\n",
      "18/18 [==============================] - 18s 984ms/step - loss: 0.0085 - accuracy: 0.9994 - val_loss: 3.6241 - val_accuracy: 0.3813\n",
      "Epoch 322/500\n",
      "18/18 [==============================] - 18s 985ms/step - loss: 0.0037 - accuracy: 0.9994 - val_loss: 3.4265 - val_accuracy: 0.3957\n",
      "Epoch 323/500\n",
      "18/18 [==============================] - 18s 978ms/step - loss: 0.0363 - accuracy: 0.9944 - val_loss: 3.3643 - val_accuracy: 0.4029\n",
      "Epoch 324/500\n",
      "18/18 [==============================] - 18s 974ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 3.4743 - val_accuracy: 0.3813\n",
      "Epoch 325/500\n",
      "18/18 [==============================] - 17s 956ms/step - loss: 0.0132 - accuracy: 0.9936 - val_loss: 3.6603 - val_accuracy: 0.3957\n",
      "Epoch 326/500\n",
      "18/18 [==============================] - 17s 960ms/step - loss: 0.0116 - accuracy: 0.9908 - val_loss: 3.8599 - val_accuracy: 0.3885\n",
      "Epoch 327/500\n",
      "18/18 [==============================] - 18s 979ms/step - loss: 0.0140 - accuracy: 0.9880 - val_loss: 3.9538 - val_accuracy: 0.3669\n",
      "Epoch 328/500\n",
      "18/18 [==============================] - 17s 956ms/step - loss: 0.0132 - accuracy: 0.9863 - val_loss: 3.8058 - val_accuracy: 0.3813\n",
      "Epoch 329/500\n",
      "18/18 [==============================] - 18s 977ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 3.8142 - val_accuracy: 0.3741\n",
      "Epoch 330/500\n",
      "18/18 [==============================] - 18s 984ms/step - loss: 0.0142 - accuracy: 0.9964 - val_loss: 3.8001 - val_accuracy: 0.3957\n",
      "Epoch 331/500\n",
      "18/18 [==============================] - 18s 994ms/step - loss: 0.0242 - accuracy: 0.9937 - val_loss: 3.6167 - val_accuracy: 0.3957\n",
      "Epoch 332/500\n",
      "18/18 [==============================] - 17s 959ms/step - loss: 0.0080 - accuracy: 0.9971 - val_loss: 3.5542 - val_accuracy: 0.3885\n",
      "Epoch 333/500\n",
      "18/18 [==============================] - 17s 941ms/step - loss: 0.0039 - accuracy: 0.9979 - val_loss: 3.5264 - val_accuracy: 0.4101\n",
      "Epoch 334/500\n",
      "18/18 [==============================] - 17s 950ms/step - loss: 0.0059 - accuracy: 0.9987 - val_loss: 3.5521 - val_accuracy: 0.4029\n",
      "Epoch 335/500\n",
      "18/18 [==============================] - 17s 931ms/step - loss: 0.0233 - accuracy: 0.9974 - val_loss: 3.6910 - val_accuracy: 0.4245\n",
      "Epoch 336/500\n",
      "18/18 [==============================] - 17s 942ms/step - loss: 0.0421 - accuracy: 0.9939 - val_loss: 4.0504 - val_accuracy: 0.3885\n",
      "Epoch 337/500\n",
      "18/18 [==============================] - 17s 936ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 4.3358 - val_accuracy: 0.3957\n",
      "Epoch 338/500\n",
      "18/18 [==============================] - 17s 961ms/step - loss: 0.0080 - accuracy: 0.9949 - val_loss: 4.7811 - val_accuracy: 0.3957\n",
      "Epoch 339/500\n",
      "18/18 [==============================] - 17s 987ms/step - loss: 0.0062 - accuracy: 0.9943 - val_loss: 4.7072 - val_accuracy: 0.4029\n",
      "Epoch 340/500\n",
      "18/18 [==============================] - 18s 1s/step - loss: 0.0379 - accuracy: 0.9917 - val_loss: 4.5131 - val_accuracy: 0.4029\n",
      "Epoch 341/500\n",
      "18/18 [==============================] - 21s 1s/step - loss: 0.0129 - accuracy: 0.9943 - val_loss: 4.2766 - val_accuracy: 0.3885\n",
      "Epoch 342/500\n",
      "18/18 [==============================] - 18s 1s/step - loss: 0.0136 - accuracy: 0.9939 - val_loss: 4.3049 - val_accuracy: 0.4101\n",
      "Epoch 343/500\n",
      "18/18 [==============================] - 19s 1s/step - loss: 0.0340 - accuracy: 0.9889 - val_loss: 4.0665 - val_accuracy: 0.4101\n",
      "Epoch 344/500\n",
      "18/18 [==============================] - 17s 964ms/step - loss: 0.0123 - accuracy: 0.9975 - val_loss: 3.9087 - val_accuracy: 0.4173\n",
      "Epoch 345/500\n",
      "18/18 [==============================] - 17s 937ms/step - loss: 0.0187 - accuracy: 0.9956 - val_loss: 3.9123 - val_accuracy: 0.3957\n",
      "Epoch 346/500\n",
      "18/18 [==============================] - 17s 933ms/step - loss: 0.0041 - accuracy: 0.9985 - val_loss: 3.9141 - val_accuracy: 0.4029\n",
      "Epoch 347/500\n",
      "18/18 [==============================] - 17s 929ms/step - loss: 0.0104 - accuracy: 0.9934 - val_loss: 3.7073 - val_accuracy: 0.3813\n",
      "Epoch 348/500\n",
      "18/18 [==============================] - 17s 958ms/step - loss: 0.0084 - accuracy: 0.9971 - val_loss: 3.7383 - val_accuracy: 0.3885\n",
      "Epoch 349/500\n",
      "18/18 [==============================] - 17s 959ms/step - loss: 0.0131 - accuracy: 1.0000 - val_loss: 3.6987 - val_accuracy: 0.3813\n",
      "Epoch 350/500\n",
      "18/18 [==============================] - 17s 932ms/step - loss: 0.0101 - accuracy: 0.9936 - val_loss: 3.7152 - val_accuracy: 0.3813\n",
      "Epoch 351/500\n",
      "18/18 [==============================] - 17s 952ms/step - loss: 0.0083 - accuracy: 0.9982 - val_loss: 3.5874 - val_accuracy: 0.3957\n",
      "Epoch 352/500\n",
      "18/18 [==============================] - 17s 960ms/step - loss: 0.0246 - accuracy: 0.9891 - val_loss: 3.6619 - val_accuracy: 0.4388\n",
      "Epoch 353/500\n",
      "18/18 [==============================] - 17s 934ms/step - loss: 0.0398 - accuracy: 0.9936 - val_loss: 4.0657 - val_accuracy: 0.4173\n",
      "Epoch 354/500\n",
      "18/18 [==============================] - 17s 940ms/step - loss: 0.0262 - accuracy: 0.9893 - val_loss: 4.2183 - val_accuracy: 0.3957\n",
      "Epoch 355/500\n",
      "18/18 [==============================] - 17s 960ms/step - loss: 0.0271 - accuracy: 0.9875 - val_loss: 3.9963 - val_accuracy: 0.3669\n",
      "Epoch 356/500\n",
      "18/18 [==============================] - 17s 942ms/step - loss: 0.0196 - accuracy: 0.9943 - val_loss: 3.8826 - val_accuracy: 0.3741\n",
      "Epoch 357/500\n",
      "18/18 [==============================] - 17s 955ms/step - loss: 0.0471 - accuracy: 0.9932 - val_loss: 3.9672 - val_accuracy: 0.3669\n",
      "Epoch 358/500\n",
      "18/18 [==============================] - 17s 949ms/step - loss: 7.6383e-04 - accuracy: 1.0000 - val_loss: 4.0044 - val_accuracy: 0.3813\n",
      "Epoch 359/500\n",
      "18/18 [==============================] - 17s 957ms/step - loss: 0.0252 - accuracy: 0.9869 - val_loss: 4.0168 - val_accuracy: 0.3813\n",
      "Epoch 360/500\n",
      "18/18 [==============================] - 17s 962ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 4.0098 - val_accuracy: 0.3597\n",
      "Epoch 361/500\n",
      "18/18 [==============================] - 17s 949ms/step - loss: 0.0055 - accuracy: 0.9972 - val_loss: 3.9964 - val_accuracy: 0.3669\n",
      "Epoch 362/500\n",
      "18/18 [==============================] - 17s 950ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 4.0405 - val_accuracy: 0.3597\n",
      "Epoch 363/500\n",
      "18/18 [==============================] - 17s 956ms/step - loss: 0.0228 - accuracy: 0.9943 - val_loss: 3.9646 - val_accuracy: 0.3669\n",
      "Epoch 364/500\n",
      "18/18 [==============================] - 17s 938ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 3.9094 - val_accuracy: 0.3741\n",
      "Epoch 365/500\n",
      "18/18 [==============================] - 17s 933ms/step - loss: 0.0233 - accuracy: 0.9875 - val_loss: 3.7233 - val_accuracy: 0.4029\n",
      "Epoch 366/500\n",
      "18/18 [==============================] - 17s 961ms/step - loss: 0.0072 - accuracy: 0.9969 - val_loss: 3.8251 - val_accuracy: 0.3957\n",
      "Epoch 367/500\n",
      "18/18 [==============================] - 17s 942ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 3.8827 - val_accuracy: 0.3957\n",
      "Epoch 368/500\n",
      "18/18 [==============================] - 17s 934ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 3.9089 - val_accuracy: 0.3885\n",
      "Epoch 369/500\n",
      "18/18 [==============================] - 17s 934ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 3.9637 - val_accuracy: 0.3957\n",
      "Epoch 370/500\n",
      "18/18 [==============================] - 17s 947ms/step - loss: 9.4954e-04 - accuracy: 0.9994 - val_loss: 3.9251 - val_accuracy: 0.4029\n",
      "Epoch 371/500\n",
      "18/18 [==============================] - 17s 951ms/step - loss: 0.0059 - accuracy: 0.9994 - val_loss: 3.8246 - val_accuracy: 0.4173\n",
      "Epoch 372/500\n",
      "18/18 [==============================] - 16s 919ms/step - loss: 0.0171 - accuracy: 0.9954 - val_loss: 3.6001 - val_accuracy: 0.4101\n",
      "Epoch 373/500\n",
      "18/18 [==============================] - 17s 932ms/step - loss: 0.0375 - accuracy: 0.9882 - val_loss: 4.0176 - val_accuracy: 0.3957\n",
      "Epoch 374/500\n",
      "18/18 [==============================] - 17s 950ms/step - loss: 0.0079 - accuracy: 0.9994 - val_loss: 3.8885 - val_accuracy: 0.3957\n",
      "Epoch 375/500\n",
      "18/18 [==============================] - 19s 1s/step - loss: 0.0540 - accuracy: 0.9888 - val_loss: 3.8429 - val_accuracy: 0.4101\n",
      "Epoch 376/500\n",
      "18/18 [==============================] - 18s 1s/step - loss: 0.0539 - accuracy: 0.9883 - val_loss: 3.7720 - val_accuracy: 0.3957\n",
      "Epoch 377/500\n",
      "18/18 [==============================] - 18s 1s/step - loss: 0.0258 - accuracy: 0.9853 - val_loss: 3.8225 - val_accuracy: 0.4029\n",
      "Epoch 378/500\n",
      "18/18 [==============================] - 18s 967ms/step - loss: 0.0198 - accuracy: 0.9941 - val_loss: 4.0948 - val_accuracy: 0.3813\n",
      "Epoch 379/500\n",
      "18/18 [==============================] - 17s 933ms/step - loss: 0.0058 - accuracy: 0.9979 - val_loss: 4.5953 - val_accuracy: 0.3885\n",
      "Epoch 380/500\n",
      "18/18 [==============================] - 17s 932ms/step - loss: 0.0242 - accuracy: 0.9834 - val_loss: 4.7463 - val_accuracy: 0.3885\n",
      "Epoch 381/500\n",
      "18/18 [==============================] - 17s 916ms/step - loss: 0.0276 - accuracy: 0.9889 - val_loss: 4.6296 - val_accuracy: 0.4029\n",
      "Epoch 382/500\n",
      "18/18 [==============================] - 17s 949ms/step - loss: 0.0069 - accuracy: 0.9923 - val_loss: 4.6833 - val_accuracy: 0.4029\n",
      "Epoch 383/500\n",
      "18/18 [==============================] - 17s 943ms/step - loss: 0.0363 - accuracy: 0.9883 - val_loss: 4.5936 - val_accuracy: 0.3813\n",
      "Epoch 384/500\n",
      "18/18 [==============================] - 17s 958ms/step - loss: 0.0050 - accuracy: 0.9977 - val_loss: 4.8482 - val_accuracy: 0.3885\n",
      "Epoch 385/500\n",
      "18/18 [==============================] - 17s 937ms/step - loss: 0.0307 - accuracy: 0.9923 - val_loss: 4.3443 - val_accuracy: 0.3957\n",
      "Epoch 386/500\n",
      "18/18 [==============================] - 17s 932ms/step - loss: 0.0090 - accuracy: 0.9967 - val_loss: 4.0775 - val_accuracy: 0.4029\n",
      "Epoch 387/500\n",
      "18/18 [==============================] - 17s 928ms/step - loss: 0.0054 - accuracy: 0.9962 - val_loss: 4.0325 - val_accuracy: 0.4029\n",
      "Epoch 388/500\n",
      "18/18 [==============================] - 17s 945ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 4.0289 - val_accuracy: 0.4029\n",
      "Epoch 389/500\n",
      "18/18 [==============================] - 17s 942ms/step - loss: 0.0342 - accuracy: 0.9911 - val_loss: 4.0211 - val_accuracy: 0.4101\n",
      "Epoch 390/500\n",
      "18/18 [==============================] - 17s 922ms/step - loss: 0.0373 - accuracy: 0.9932 - val_loss: 4.0219 - val_accuracy: 0.4101\n",
      "Epoch 391/500\n",
      "18/18 [==============================] - 17s 949ms/step - loss: 0.0123 - accuracy: 0.9921 - val_loss: 3.9443 - val_accuracy: 0.3957\n",
      "Epoch 392/500\n",
      "18/18 [==============================] - 17s 961ms/step - loss: 0.0058 - accuracy: 0.9982 - val_loss: 3.9499 - val_accuracy: 0.4101\n",
      "Epoch 393/500\n",
      "18/18 [==============================] - 17s 924ms/step - loss: 0.0216 - accuracy: 0.9924 - val_loss: 3.9663 - val_accuracy: 0.3957\n",
      "Epoch 394/500\n",
      "18/18 [==============================] - 17s 942ms/step - loss: 0.0163 - accuracy: 0.9942 - val_loss: 3.9452 - val_accuracy: 0.3885\n",
      "Epoch 395/500\n",
      "18/18 [==============================] - 17s 955ms/step - loss: 0.0112 - accuracy: 0.9964 - val_loss: 4.0008 - val_accuracy: 0.3957\n",
      "Epoch 396/500\n",
      "18/18 [==============================] - 17s 933ms/step - loss: 0.0105 - accuracy: 0.9977 - val_loss: 4.0936 - val_accuracy: 0.3741\n",
      "Epoch 397/500\n",
      "18/18 [==============================] - 17s 959ms/step - loss: 0.0689 - accuracy: 0.9787 - val_loss: 4.4806 - val_accuracy: 0.3957\n",
      "Epoch 398/500\n",
      "18/18 [==============================] - 17s 926ms/step - loss: 0.0342 - accuracy: 0.9900 - val_loss: 4.7864 - val_accuracy: 0.3957\n",
      "Epoch 399/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 17s 946ms/step - loss: 0.1127 - accuracy: 0.9832 - val_loss: 5.6014 - val_accuracy: 0.3669\n",
      "Epoch 400/500\n",
      "18/18 [==============================] - 17s 952ms/step - loss: 0.0235 - accuracy: 0.9825 - val_loss: 5.3605 - val_accuracy: 0.3813\n",
      "Epoch 401/500\n",
      "18/18 [==============================] - 17s 938ms/step - loss: 0.0358 - accuracy: 0.9861 - val_loss: 5.2594 - val_accuracy: 0.4173\n",
      "Epoch 402/500\n",
      "18/18 [==============================] - 17s 928ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 5.2328 - val_accuracy: 0.4101\n",
      "Epoch 403/500\n",
      "18/18 [==============================] - 17s 921ms/step - loss: 0.0086 - accuracy: 0.9996 - val_loss: 5.2594 - val_accuracy: 0.4101\n",
      "Epoch 404/500\n",
      "18/18 [==============================] - 17s 929ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 5.1737 - val_accuracy: 0.3885\n",
      "Epoch 405/500\n",
      "18/18 [==============================] - 17s 923ms/step - loss: 0.0101 - accuracy: 0.9952 - val_loss: 5.2861 - val_accuracy: 0.3741\n",
      "Epoch 406/500\n",
      "18/18 [==============================] - 17s 945ms/step - loss: 0.0210 - accuracy: 0.9945 - val_loss: 5.3667 - val_accuracy: 0.4029\n",
      "Epoch 407/500\n",
      "18/18 [==============================] - 17s 948ms/step - loss: 0.0310 - accuracy: 0.9950 - val_loss: 5.2996 - val_accuracy: 0.3885\n",
      "Epoch 408/500\n",
      "18/18 [==============================] - 17s 925ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 4.8237 - val_accuracy: 0.3885\n",
      "Epoch 409/500\n",
      "18/18 [==============================] - 17s 935ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 4.7719 - val_accuracy: 0.3957\n",
      "Epoch 410/500\n",
      "18/18 [==============================] - 18s 1s/step - loss: 0.0109 - accuracy: 0.9979 - val_loss: 4.7409 - val_accuracy: 0.4029\n",
      "Epoch 411/500\n",
      "18/18 [==============================] - 18s 992ms/step - loss: 0.0172 - accuracy: 0.9871 - val_loss: 4.9408 - val_accuracy: 0.4173\n",
      "Epoch 412/500\n",
      "18/18 [==============================] - 19s 1s/step - loss: 0.0150 - accuracy: 0.9955 - val_loss: 4.9330 - val_accuracy: 0.4173\n",
      "Epoch 413/500\n",
      "18/18 [==============================] - 18s 1s/step - loss: 0.0117 - accuracy: 0.9916 - val_loss: 4.9146 - val_accuracy: 0.4460\n",
      "Epoch 414/500\n",
      "18/18 [==============================] - 17s 929ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 4.9112 - val_accuracy: 0.4460\n",
      "Epoch 415/500\n",
      "18/18 [==============================] - 17s 937ms/step - loss: 0.0102 - accuracy: 0.9986 - val_loss: 4.9301 - val_accuracy: 0.4460\n",
      "Epoch 416/500\n",
      "18/18 [==============================] - 17s 957ms/step - loss: 0.0047 - accuracy: 0.9966 - val_loss: 4.8483 - val_accuracy: 0.4317\n",
      "Epoch 417/500\n",
      "18/18 [==============================] - 17s 940ms/step - loss: 0.0404 - accuracy: 0.9883 - val_loss: 4.2926 - val_accuracy: 0.4532\n",
      "Epoch 418/500\n",
      "18/18 [==============================] - 17s 944ms/step - loss: 0.0068 - accuracy: 0.9960 - val_loss: 4.4666 - val_accuracy: 0.4245\n",
      "Epoch 419/500\n",
      "18/18 [==============================] - 17s 930ms/step - loss: 0.0058 - accuracy: 0.9985 - val_loss: 4.5234 - val_accuracy: 0.4317\n",
      "Epoch 420/500\n",
      "18/18 [==============================] - 17s 929ms/step - loss: 0.0210 - accuracy: 0.9910 - val_loss: 4.5468 - val_accuracy: 0.4101\n",
      "Epoch 421/500\n",
      "18/18 [==============================] - 17s 950ms/step - loss: 0.0168 - accuracy: 0.9924 - val_loss: 4.4441 - val_accuracy: 0.4245\n",
      "Epoch 422/500\n",
      "18/18 [==============================] - 17s 946ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 4.3947 - val_accuracy: 0.4173\n",
      "Epoch 423/500\n",
      "18/18 [==============================] - 17s 927ms/step - loss: 0.0324 - accuracy: 0.9923 - val_loss: 4.7426 - val_accuracy: 0.4029\n",
      "Epoch 424/500\n",
      "18/18 [==============================] - 17s 921ms/step - loss: 0.0072 - accuracy: 0.9975 - val_loss: 5.0669 - val_accuracy: 0.4101\n",
      "Epoch 425/500\n",
      "18/18 [==============================] - 17s 944ms/step - loss: 0.0296 - accuracy: 0.9888 - val_loss: 4.5543 - val_accuracy: 0.4173\n",
      "Epoch 426/500\n",
      "18/18 [==============================] - 17s 950ms/step - loss: 0.0096 - accuracy: 0.9967 - val_loss: 4.6938 - val_accuracy: 0.3885\n",
      "Epoch 427/500\n",
      "18/18 [==============================] - 17s 969ms/step - loss: 0.0075 - accuracy: 0.9990 - val_loss: 4.9436 - val_accuracy: 0.3885\n",
      "Epoch 428/500\n",
      "18/18 [==============================] - 17s 953ms/step - loss: 0.0058 - accuracy: 0.9968 - val_loss: 4.9335 - val_accuracy: 0.3885\n",
      "Epoch 429/500\n",
      "18/18 [==============================] - 17s 943ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 4.8980 - val_accuracy: 0.3957\n",
      "Epoch 430/500\n",
      "18/18 [==============================] - 17s 940ms/step - loss: 0.0302 - accuracy: 0.9834 - val_loss: 5.1746 - val_accuracy: 0.4101\n",
      "Epoch 431/500\n",
      "18/18 [==============================] - 18s 973ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 5.1348 - val_accuracy: 0.4245\n",
      "Epoch 432/500\n",
      "18/18 [==============================] - 17s 964ms/step - loss: 0.0104 - accuracy: 0.9960 - val_loss: 5.1571 - val_accuracy: 0.4317\n",
      "Epoch 433/500\n",
      "18/18 [==============================] - 17s 940ms/step - loss: 0.0315 - accuracy: 0.9815 - val_loss: 5.0282 - val_accuracy: 0.4029\n",
      "Epoch 434/500\n",
      "18/18 [==============================] - 17s 965ms/step - loss: 7.8366e-04 - accuracy: 1.0000 - val_loss: 4.9472 - val_accuracy: 0.4029\n",
      "Epoch 435/500\n",
      "18/18 [==============================] - 17s 951ms/step - loss: 0.0323 - accuracy: 0.9819 - val_loss: 4.6381 - val_accuracy: 0.3957\n",
      "Epoch 436/500\n",
      "18/18 [==============================] - 17s 959ms/step - loss: 0.0108 - accuracy: 0.9968 - val_loss: 4.5247 - val_accuracy: 0.4173\n",
      "Epoch 437/500\n",
      "18/18 [==============================] - 17s 948ms/step - loss: 0.0114 - accuracy: 0.9892 - val_loss: 4.2461 - val_accuracy: 0.4173\n",
      "Epoch 438/500\n",
      "18/18 [==============================] - 17s 956ms/step - loss: 0.0196 - accuracy: 0.9869 - val_loss: 4.1326 - val_accuracy: 0.4173\n",
      "Epoch 439/500\n",
      "18/18 [==============================] - 17s 933ms/step - loss: 0.0101 - accuracy: 0.9924 - val_loss: 4.1392 - val_accuracy: 0.4173\n",
      "Epoch 440/500\n",
      "18/18 [==============================] - 17s 957ms/step - loss: 0.0061 - accuracy: 0.9979 - val_loss: 4.1882 - val_accuracy: 0.4029\n",
      "Epoch 441/500\n",
      "18/18 [==============================] - 17s 954ms/step - loss: 0.0065 - accuracy: 0.9963 - val_loss: 4.3285 - val_accuracy: 0.4029\n",
      "Epoch 442/500\n",
      "18/18 [==============================] - 17s 963ms/step - loss: 0.0422 - accuracy: 0.9899 - val_loss: 4.9321 - val_accuracy: 0.4029\n",
      "Epoch 443/500\n",
      "18/18 [==============================] - 17s 942ms/step - loss: 0.0727 - accuracy: 0.9858 - val_loss: 5.1585 - val_accuracy: 0.3741\n",
      "Epoch 444/500\n",
      "18/18 [==============================] - 17s 962ms/step - loss: 0.0168 - accuracy: 0.9927 - val_loss: 5.0195 - val_accuracy: 0.3885\n",
      "Epoch 445/500\n",
      "18/18 [==============================] - 20s 1s/step - loss: 0.0169 - accuracy: 0.9965 - val_loss: 4.9788 - val_accuracy: 0.3885\n",
      "Epoch 446/500\n",
      "18/18 [==============================] - 20s 1s/step - loss: 0.0030 - accuracy: 0.9975 - val_loss: 4.9525 - val_accuracy: 0.4101\n",
      "Epoch 447/500\n",
      "18/18 [==============================] - 19s 1s/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 4.9616 - val_accuracy: 0.4029\n",
      "Epoch 448/500\n",
      "18/18 [==============================] - 18s 1s/step - loss: 0.0148 - accuracy: 0.9927 - val_loss: 4.8440 - val_accuracy: 0.4029\n",
      "Epoch 449/500\n",
      "18/18 [==============================] - 17s 943ms/step - loss: 0.0070 - accuracy: 0.9963 - val_loss: 4.7797 - val_accuracy: 0.4029\n",
      "Epoch 450/500\n",
      "18/18 [==============================] - 17s 943ms/step - loss: 0.0122 - accuracy: 0.9968 - val_loss: 4.8245 - val_accuracy: 0.3957\n",
      "Epoch 451/500\n",
      "18/18 [==============================] - 17s 953ms/step - loss: 7.4905e-04 - accuracy: 1.0000 - val_loss: 4.8437 - val_accuracy: 0.3957\n",
      "Epoch 452/500\n",
      "18/18 [==============================] - 17s 970ms/step - loss: 0.0105 - accuracy: 0.9972 - val_loss: 4.7968 - val_accuracy: 0.3957\n",
      "Epoch 453/500\n",
      "18/18 [==============================] - 17s 946ms/step - loss: 0.0021 - accuracy: 0.9996 - val_loss: 4.7945 - val_accuracy: 0.4029\n",
      "Epoch 454/500\n",
      "18/18 [==============================] - 17s 945ms/step - loss: 0.0301 - accuracy: 0.9932 - val_loss: 4.9174 - val_accuracy: 0.4173\n",
      "Epoch 455/500\n",
      "18/18 [==============================] - 17s 951ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 4.9110 - val_accuracy: 0.4245\n",
      "Epoch 456/500\n",
      "18/18 [==============================] - 17s 956ms/step - loss: 0.0022 - accuracy: 0.9988 - val_loss: 4.8660 - val_accuracy: 0.4245\n",
      "Epoch 457/500\n",
      "18/18 [==============================] - 17s 933ms/step - loss: 0.0318 - accuracy: 0.9918 - val_loss: 4.7642 - val_accuracy: 0.4173\n",
      "Epoch 458/500\n",
      "18/18 [==============================] - 17s 943ms/step - loss: 0.0261 - accuracy: 0.9898 - val_loss: 5.0373 - val_accuracy: 0.4245\n",
      "Epoch 459/500\n",
      "18/18 [==============================] - 17s 955ms/step - loss: 0.0048 - accuracy: 0.9988 - val_loss: 4.9976 - val_accuracy: 0.4173\n",
      "Epoch 460/500\n",
      "18/18 [==============================] - 17s 951ms/step - loss: 0.0219 - accuracy: 0.9855 - val_loss: 5.0067 - val_accuracy: 0.4245\n",
      "Epoch 461/500\n",
      "18/18 [==============================] - 17s 949ms/step - loss: 0.0462 - accuracy: 0.9755 - val_loss: 4.6433 - val_accuracy: 0.4245\n",
      "Epoch 462/500\n",
      "18/18 [==============================] - 17s 951ms/step - loss: 0.0287 - accuracy: 0.9924 - val_loss: 4.3084 - val_accuracy: 0.4317\n",
      "Epoch 463/500\n",
      "18/18 [==============================] - 17s 934ms/step - loss: 0.0038 - accuracy: 0.9987 - val_loss: 4.3755 - val_accuracy: 0.4245\n",
      "Epoch 464/500\n",
      "18/18 [==============================] - 17s 940ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 4.5196 - val_accuracy: 0.4245\n",
      "Epoch 465/500\n",
      "18/18 [==============================] - 17s 961ms/step - loss: 0.0087 - accuracy: 0.9953 - val_loss: 4.5134 - val_accuracy: 0.4317\n",
      "Epoch 466/500\n",
      "18/18 [==============================] - 17s 943ms/step - loss: 0.0048 - accuracy: 0.9996 - val_loss: 4.5144 - val_accuracy: 0.4388\n",
      "Epoch 467/500\n",
      "18/18 [==============================] - 17s 940ms/step - loss: 3.3798e-04 - accuracy: 1.0000 - val_loss: 4.5253 - val_accuracy: 0.4317\n",
      "Epoch 468/500\n",
      "18/18 [==============================] - 17s 957ms/step - loss: 0.0056 - accuracy: 0.9967 - val_loss: 4.5339 - val_accuracy: 0.4101\n",
      "Epoch 469/500\n",
      "18/18 [==============================] - 17s 947ms/step - loss: 0.0155 - accuracy: 0.9952 - val_loss: 4.2711 - val_accuracy: 0.4101\n",
      "Epoch 470/500\n",
      "18/18 [==============================] - 17s 931ms/step - loss: 7.2863e-04 - accuracy: 0.9994 - val_loss: 4.1570 - val_accuracy: 0.4460\n",
      "Epoch 471/500\n",
      "18/18 [==============================] - 17s 926ms/step - loss: 2.7582e-04 - accuracy: 1.0000 - val_loss: 4.0367 - val_accuracy: 0.4460\n",
      "Epoch 472/500\n",
      "18/18 [==============================] - 17s 948ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 4.0499 - val_accuracy: 0.4604\n",
      "Epoch 473/500\n",
      "18/18 [==============================] - 17s 946ms/step - loss: 6.2646e-04 - accuracy: 1.0000 - val_loss: 4.0440 - val_accuracy: 0.4604\n",
      "Epoch 474/500\n",
      "18/18 [==============================] - 17s 943ms/step - loss: 0.1226 - accuracy: 0.9718 - val_loss: 3.8663 - val_accuracy: 0.4604\n",
      "Epoch 475/500\n",
      "18/18 [==============================] - 17s 967ms/step - loss: 0.0041 - accuracy: 0.9970 - val_loss: 3.7114 - val_accuracy: 0.4604\n",
      "Epoch 476/500\n",
      "18/18 [==============================] - 17s 942ms/step - loss: 0.0086 - accuracy: 0.9952 - val_loss: 3.6178 - val_accuracy: 0.4604\n",
      "Epoch 477/500\n",
      "18/18 [==============================] - 17s 934ms/step - loss: 0.0088 - accuracy: 0.9932 - val_loss: 3.6236 - val_accuracy: 0.4676\n",
      "Epoch 478/500\n",
      "18/18 [==============================] - 17s 936ms/step - loss: 0.0059 - accuracy: 0.9975 - val_loss: 3.6411 - val_accuracy: 0.4532\n",
      "Epoch 479/500\n",
      "18/18 [==============================] - 17s 969ms/step - loss: 0.0102 - accuracy: 0.9957 - val_loss: 3.7076 - val_accuracy: 0.4532\n",
      "Epoch 480/500\n",
      "18/18 [==============================] - 18s 1s/step - loss: 0.0201 - accuracy: 0.9847 - val_loss: 3.8767 - val_accuracy: 0.4460\n",
      "Epoch 481/500\n",
      "18/18 [==============================] - 18s 1s/step - loss: 0.0021 - accuracy: 0.9990 - val_loss: 4.0077 - val_accuracy: 0.4317\n",
      "Epoch 482/500\n",
      "18/18 [==============================] - 19s 1s/step - loss: 0.0067 - accuracy: 0.9994 - val_loss: 4.0428 - val_accuracy: 0.4317\n",
      "Epoch 483/500\n",
      "18/18 [==============================] - 17s 962ms/step - loss: 0.0721 - accuracy: 0.9898 - val_loss: 4.1883 - val_accuracy: 0.4532\n",
      "Epoch 484/500\n",
      "18/18 [==============================] - 17s 951ms/step - loss: 0.0093 - accuracy: 0.9910 - val_loss: 4.2236 - val_accuracy: 0.4317\n",
      "Epoch 485/500\n",
      "18/18 [==============================] - 17s 948ms/step - loss: 0.0174 - accuracy: 0.9958 - val_loss: 4.4458 - val_accuracy: 0.4101\n",
      "Epoch 486/500\n",
      "18/18 [==============================] - 17s 933ms/step - loss: 0.0031 - accuracy: 0.9987 - val_loss: 4.4669 - val_accuracy: 0.4029\n",
      "Epoch 487/500\n",
      "18/18 [==============================] - 17s 966ms/step - loss: 9.3567e-04 - accuracy: 1.0000 - val_loss: 4.4462 - val_accuracy: 0.4101\n",
      "Epoch 488/500\n",
      "18/18 [==============================] - 17s 926ms/step - loss: 0.1311 - accuracy: 0.9890 - val_loss: 4.4911 - val_accuracy: 0.4173\n",
      "Epoch 489/500\n",
      "18/18 [==============================] - 17s 954ms/step - loss: 0.0080 - accuracy: 0.9992 - val_loss: 4.5244 - val_accuracy: 0.4101\n",
      "Epoch 490/500\n",
      "18/18 [==============================] - 17s 962ms/step - loss: 0.0129 - accuracy: 0.9967 - val_loss: 4.5446 - val_accuracy: 0.4245\n",
      "Epoch 491/500\n",
      "18/18 [==============================] - 17s 944ms/step - loss: 1.4662e-04 - accuracy: 1.0000 - val_loss: 4.5387 - val_accuracy: 0.4245\n",
      "Epoch 492/500\n",
      "18/18 [==============================] - 17s 936ms/step - loss: 0.0026 - accuracy: 0.9979 - val_loss: 4.5383 - val_accuracy: 0.4245\n",
      "Epoch 493/500\n",
      "18/18 [==============================] - 17s 934ms/step - loss: 0.0494 - accuracy: 0.9844 - val_loss: 4.7005 - val_accuracy: 0.4317\n",
      "Epoch 494/500\n",
      "18/18 [==============================] - 17s 950ms/step - loss: 0.0701 - accuracy: 0.9870 - val_loss: 4.6810 - val_accuracy: 0.4245\n",
      "Epoch 495/500\n",
      "18/18 [==============================] - 17s 960ms/step - loss: 0.0149 - accuracy: 0.9914 - val_loss: 4.8998 - val_accuracy: 0.4388\n",
      "Epoch 496/500\n",
      "18/18 [==============================] - 19s 1s/step - loss: 0.0309 - accuracy: 0.9930 - val_loss: 4.6156 - val_accuracy: 0.4173\n",
      "Epoch 497/500\n",
      "18/18 [==============================] - 17s 950ms/step - loss: 0.0053 - accuracy: 0.9988 - val_loss: 4.5326 - val_accuracy: 0.4173\n",
      "Epoch 498/500\n",
      "18/18 [==============================] - 17s 945ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 4.4561 - val_accuracy: 0.4317\n",
      "Epoch 499/500\n",
      "18/18 [==============================] - 17s 941ms/step - loss: 0.0322 - accuracy: 0.9847 - val_loss: 4.4922 - val_accuracy: 0.4388\n",
      "Epoch 500/500\n",
      "18/18 [==============================] - 17s 937ms/step - loss: 0.0623 - accuracy: 0.9934 - val_loss: 4.6599 - val_accuracy: 0.4173\n"
     ]
    }
   ],
   "source": [
    "history = model.fit( \n",
    "    train_data_gen, \n",
    "    steps_per_epoch = TRAIN_STEPS, \n",
    "    epochs = EPOCHS,\n",
    "#     callbacks = callbacks, \n",
    "    validation_data = valid_data_gen, \n",
    "    validation_steps = VALIDATION_STEPS) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_metrics(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "model.save(\"cnn_opt_norm_feature.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 - 2s - loss: 4.6599 - accuracy: 0.4173\n"
     ]
    }
   ],
   "source": [
    "# evaluate model on validation data\n",
    "score = model.evaluate(valid_data_gen, steps = VALIDATION_STEPS, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 4.659910202026367 / Validation accuracy: 0.41726619005203247\n"
     ]
    }
   ],
   "source": [
    "print(f'Validation loss: {score[0]} / Validation accuracy: {score[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 - 1s - loss: 3.9206 - accuracy: 0.4800\n"
     ]
    }
   ],
   "source": [
    "# evaluate model on test data\n",
    "score = model.evaluate(test_data_gen, steps = TEST_STEPS, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 3.9206342697143555 / Test accuracy: 0.47999998927116394\n"
     ]
    }
   ],
   "source": [
    "print(f'Test loss: {score[0]} / Test accuracy: {score[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
